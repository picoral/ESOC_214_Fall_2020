% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={ESOC 2014 Introduction to Data Science},
  pdfauthor={Adriana Picoral, PhD (she/her)  adrianaps@email.arizona.edu},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{ESOC 2014 Introduction to Data Science}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Fall 2020}
\author{Adriana Picoral, PhD (she/her) \href{mailto:adrianaps@email.arizona.edu}{\nolinkurl{adrianaps@email.arizona.edu}}}
\date{2020-11-25}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{syllabus}{%
\chapter{Syllabus}\label{syllabus}}

The University of Arizona sits on the homelands of the Tohono O'odham and Pascua Yaqui, whose care and keeping of these lands allows us to be here today. Territory acknowledgements are one small part of disrupting and dismantling colonial structures.

This syllabus is subject to change if need arises.

\textbf{There are two sections of this course}

Tuesday \& Thursday 12:30pm - 1:45pm

\begin{itemize}
\tightlist
\item
  Final Exam Date: December 16 (Wednesday) 1:00pm - 3:00pm
\end{itemize}

Tuesday \& Thursday 2:00pm - 3:15pm

\begin{itemize}
\tightlist
\item
  Final Exam Date: December 14 (Monday) 3:30pm - 5:30pm
\end{itemize}

\textbf{Office Hours/Free help session/Work time}

\begin{itemize}
\tightlist
\item
  Tuesday 9:30am - 11:00am \& Wednesday 1:00pm - 2:30pm
\end{itemize}

\hypertarget{course-description}{%
\section{Course Description}\label{course-description}}

This course provides an introduction to the various skills and considerations required for data management and analysis in business, education, and science. Particular attention will be given to learning how to use the free and open-source computing environment R, focusing on the \texttt{tidyverse} package for data science. This course is designed to be interactive and hands-on.

\hypertarget{course-objectives}{%
\section{Course Objectives}\label{course-objectives}}

This course aims at providing students with an understanding of the various steps in the data science workflow. Students will engage in data wrangling and exploration to provide answers to questions about the data, using the R programming language. During the semester students will work on an individual data science project to be presented to the class.

\hypertarget{learning-outcomes}{%
\section{Learning Outcomes}\label{learning-outcomes}}

At the end of this course, students will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Apply the different steps of data science as a process to derive knowledge from data

  1.1. form the question to be answered

  1.2. acquire the data to answer question

  1.3. transform and tidy data so that data analysis is possible

  1.4. explore data with understanding as the goal, which includes data visualization

  1.5. communicate data analysis results
\item
  Demonstrate proficiency of the steps 1.3 - 1.5 above in the R programming language and R Markdown
\item
  Identify and apply professional standards regarding all aspects of data ethics and privacy, including how data are stored, used, managed, analyzed, and presented
\item
  Demonstrate knowledge of what a data scientist is and what a career in data science requires in terms of education, and set goals and make plans in case they want to pursue data science beyond the completion of this course
\end{enumerate}

Please refer to the \href{https://ischool.arizona.edu/undergraduate-student-competencies}{department's undergraduate student competencies} to find out how this course's learning outcomes fit into your broad education goals.

\hypertarget{a-few-words-on-r-and-coding}{%
\section{A Few Words on R and Coding}\label{a-few-words-on-r-and-coding}}

This course will be based around the programming language R which we will use within the integrated development environment (IDE) R Studio. For many of you this will be the first time programming, \textbf{AND THAT'S OK! This course is intended for beginners, and we will actively focus on building up your R skills over the course of the semester}. Of course, there will still be challenges along the way, but you will rapidly figure out how to solve your own problems as well as to apply your current knowledge to new and exciting questions. If you are struggling I highly encourage you to take advantage of my free help sessions (see times above). Of course, Google is always a super helpful way to get insight into coding problems. Our class Slack channel will also be there so you can help each other out. You might want to watch \href{https://www.youtube.com/watch?v=ZFaWxxzouCY}{Roger Peng's video on how to get help}, which contains guidelines on what information to provide when asking a question in a public forum.

I also want to note that I highly encourage you to help each other, as data scientists are rarely working in isolation. \textbf{This does not mean you can directly share code associated with an assignment (this is a violation of UA's Code of Academic Integrity)}. What it does mean is that it is helpful to talk to each other about problems you encountered, resources you found, or provide helpful tips.

Learning to code nowadays is much easier, since a simple Google search will research in a huge amount of code that can solve any number of problems. You may use online resources (e.g., StackOverflow), but we will go over the syntax needed to solve all assignments in class. If you do use any external resources, you must explicitly cite where the code was obtained in your comments (add a direct link to the resource). I'll be checking for recycled code, and any code you re-used without a proper citation will be treated as plagiarism.

\hypertarget{a-few-words-on-technology}{%
\section{A Few Words on Technology}\label{a-few-words-on-technology}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  YOU MUST HAVE ACCESS TO A COMPUTER YOU CAN CODE WITH IN EVERY CLASS! We will be actively coding in R on a daily basis, and not being able to follow along will severely hamper your learning. If you do not have a laptop or yours had troubles at some point during the semester, the library offers fast and free rentals of both macs and PCs: \url{https://new.library.arizona.edu/tech/borrow}. You can also take advantage of the multiple computer labs on campus: \url{https://it.arizona.edu/service/oscr-computer-labs}
\item
  You will have access to and will be required to retrieve all course materials from the course page on GitHub.
\item
  You will need to have R and R Studio installed and functioning by the second day of class. We will go over what these programs are and how to install them in the first week of class.
\item
  Slack participation is critical! If you are having a coding issue, first try and solve it on your own. If you're still struggling, then post it to our Slack. Essentially, if you are about to email me with a homework/class/coding question, post it to Slack first. I'm not doing this to save me time, but rather because virtually all programmers/coders solve problems by helping each other, and thus I want you to do the same! Please \href{https://join.slack.com/t/ischool-esoc214/shared_invite/zt-gbmjw9oz-8hcl5iuktuYYdsamAkPVQA}{register for our Slack channel}.
\end{enumerate}

\hypertarget{readings}{%
\section{Readings}\label{readings}}

There is no required textbook for this class. A few times we will use the book ``R for Data Science'' by Hadley Wickham and Garret Grolemund. This book covers how to create full data science pipelines in R (more than we'll be doing here) and is available free here: \url{https://r4ds.had.co.nz/}.

Aside from this book, there will be other required readings. I will link these readings for you on this bookdown. Some come from academic journals, and others are news articles that appear in many of the newspapers you read in print and online. For each reading, a word count and an approximate reading time will be provided. Please adjust these approximations to your own reading time, so you can plan accordingly.

It is crucial that you read all assigned readings to do well in this class. Anyone who has not done the reading will simply not be able to participate.

\hypertarget{assignments-with-grade-breakdown}{%
\section{Assignments with Grade Breakdown}\label{assignments-with-grade-breakdown}}

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright
Activity\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
Total Percent\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
Unit Percent\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Final Project\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
30\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
5\% Project Proposal 15\% \href{https://classroom.github.com/a/J-8vd5iB}{Write-up} 10\% Oral presentation\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
This will be a full data science project, complete with formal write-up and presentation to the class\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Midterm\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
20\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
20\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Sharing Code during Zoom sections (5)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
10\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Data Challenges (9)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
28\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
3.5\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Lowest will be dropped. All assignments must completed by the date and time provided in the assignment instructions\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Class Participation\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
10\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Participation includes both in-class and message board questions, engagement. To get full credit I should see your name or hear you in class once a week.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Intro and exit surveys\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
1\%\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Late assignments within 24 hours of due date and time will get a 20\% grade penalty. Assignments submitted 24 hours after the due date and time will not get any credit.

If you are unable to complete an assignment on the due date due to an illness or another personal problem, please contact me as soon as possible so we can talk about ways to help you complete that assignment.

Any work turned in for this class needs to be distinctly developed for this class, and not work turned in for other classes.

Grade Distribution:

90-100\% = A ``exemplary, far beyond reqs/expectations''

80-89\% = B ``exceeds requirements/expectations''

70-79\% = C ``meets requirements/expectations''

60-69\% = D ``falls short of requirements/expectations''

\textless{} 60\% = E ``repeat of course needed''

\textbf{A Note About Final Grades}

I do not modify final grades. I have designed this course to be highly passable for the new learner assuming they do the modest homework assignments, come to class, and participate. I'm not a difficult grader, and I build in extensive opportunities for `easy points.' Given all this, please do not try and ask for a higher grade when end of semester rolls around.

\hypertarget{requirements-for-the-course}{%
\section{Requirements for the Course}\label{requirements-for-the-course}}

To succeed in this course, 2-3 hours of study time per hour of formal class time (or per unit) are required. This means that in addition to our three hours of formal class meeting time, 6-9 hours a week of study time are needed in order to meet course expectations. These hours should be spent on reading texts, working on your data challenges, researching for new information, or thinking about course content.

\textbf{It's important to mention that each lesson builds upon the previous, and thus staying on top of the material is critical to your success.} As mentioned before, this class is built specifically for beginners, and plenty of students who have never coded before have done extremely well. But, the reason they did is that they came to class consistently, asked questions when they had an issue, and completed their data challenges. If you miss a class, come to office hours to make up what you missed. I will do everything possible to make sure you succeeded assuming you're willing to put in the work!

\hypertarget{course-schedule}{%
\section{Course Schedule}\label{course-schedule}}

Here is the tentative course schedule. \textbf{Data challenges are always due before the start of class on the associated due date}. There will sometimes be other short readings and assignments. These will be posted on D2L directly after the class period in which they are assigned.

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright
Week\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
Date\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
Goals\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
Assignment\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 01\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-08-25\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Introductions Syllabus\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-08-27\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Intro do Data Science Data Science workflow\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Reading: \href{readings/module2_what_is_data_science.pdf}{What's data science?} (20 min) YouTube video \href{https://youtu.be/6OFm7YcunWc?t=617}{Angry Hiring Manager Panel} (6.5 min) \href{https://forms.gle/NaqrC87cB8xh6Sdz8}{Survey 1} (10 min)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 02\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-01\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
What's Data? What does data analysis look like? IDE overview How and Why to Start a Project Basics of R\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Reading: \href{readings/module2_eds_leek_whatsdatascience.pdf}{Data Science examples} (8 min), \href{readings/module2_modern_data_science_data_intake.pdf}{Data Intake} (12 min) \protect\hyperlink{install-r}{Install R and RStudio}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-03\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Basics of R - basic operations - objects - data types\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 03\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-08\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Basics of R - data frames - inspecting data - slicing your data\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Read \href{http://varianceexplained.org/programming/bad-code/}{A Million Lines of Bad Code} (5 min) \href{readings/module7_eds_whats_stats.pdf}{What is Statistics Good For?} (3 min)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-10\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Submitting assignments through GitHub\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/uE1b8ho7}{Join our GitHub classroom}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 04\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-15\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Installing R Packages Intro to Tidyverse\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Read \href{https://www.r-bloggers.com/advice-to-young-and-old-programmers-a-conversation-with-hadley-wickham/}{Advice to Young (and Old) Programmers: A Conversation with Hadley Wickham} (10 min) \href{https://classroom.github.com/a/uE1b8ho7}{Submit test assignment}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-17\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Tidyverse\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 05\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-22\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data Wrangling\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/0CjzlvtW}{Data Challenge 1}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-24\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data Wrangling\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 06\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-09-29\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Intro to Data Visualization\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/DhH5ciNQ}{Data Challenge 2}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-01\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data Visualization\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 07\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-06\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data Visualization\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/ndGrSqaq}{Data Challenge 3}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-08\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data Visualization\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 08\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-13\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data analysis case study 1\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/fYDB-CfS}{Data Challenge 4}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-15\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data analysis case study 1\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 09\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-20\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/7uCUExMy}{MIDTERM} - Study Guide on D2L\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/6eey650g}{Data Challenge 5}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-22\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data analysis case study 2\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 10\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-27\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data analysis case study 2\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-10-29\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Getting Data\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/6RuMwg7C}{Data Challenge 6}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 11\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-03\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data analysis case study 3\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Deadline to meet about final project\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-05\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Data analysis case study 3\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{final_project_docs/esoc214_project_proposal.pdf}{Project Proposal}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 12\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-10\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Markdown\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/3-61nsVd}{Data Challenge 7}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-12\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Markdown\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 13\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-17\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Full data analysis case study 4\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/hsqRqRx1}{Data Challenge 8}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-19\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Full data analysis case study 4\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 14\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-24\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Happy Thanksgiving! 🌽🦃🏡\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/J1bexrCQ}{Data Challenge 9}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-11-26\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Happy Thanksgiving! 🌽🦃🏡\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 15\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-12-01\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Written and Oral Communication in Data Science\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-12-03\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Written and Oral Communication in Data Science\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Week 16\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
2020-12-08\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
Preparing for Final Presentations Wrap-up\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\href{https://classroom.github.com/a/J-8vd5iB}{Final Project} is due December 16 (Wednesday) at 3:00pm\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

For more information about dates including holidays, check \href{https://catalog.arizona.edu/calendar/2020-2021-academic-calendar}{UArizona's Academic Calendar}.

\textbf{Why am I using YYYY-MM-DD date format?}

\includegraphics[width=10.89in]{images/iso_8601_2x}

\href{https://xkcd.com/1179/}{ISO 8601 -- xkcd}

\hypertarget{final-project}{%
\section{Final Project}\label{final-project}}

There is a final project in place of a final exam for this class. You will find your own dataset that helps you answer a question that you're interested in. You'll bring these data into R, explore it, clean it, make features, and run an analysis that allows you to answer your question. You will be graded on the completed R script as well as your presentation of the data.

The presentation will last 3-4 minutes, and will take place on the day of the final exam (in place of the exam). University policy on final examinations can be found here: \url{https://www.registrar.arizona.edu/courses/final-examination-regulations-and-information}

\hypertarget{honors-students-requirements}{%
\section{Honors Students' Requirements}\label{honors-students-requirements}}

Students wishing to take this course for Honors Credit should email me to set up an appointment to discuss the terms of the contact and to sign the Honors Course Contract Request Form. The form is available at \url{https://honors.arizona.edu/academics/honors-contracts}. Students earning credit with the University of Arizona Honors College will be held to the following enhancements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Honors students will be required to create an academic poster based on their final project, and then present this poster at the iSchool's iShowcase at the end of the semester. Creating a poster will require extra work to ensure clarity of logic, having a well-defined question and approach, and the creation of quality visuals. Guidelines on how to create an engaging academic poster can be found here: \url{https://guides.nyu.edu/posters}. Note: The iShowcase is at the end of the semester, but before finals when the regular class will have the project due. Thus, you will have to be ahead of schedule a bit to meet your honors requirement.
\item
  Honors students will also be expected to informally `journal' about the course each week. Each week, that is, students will be required to write a five-sentence paragraph reflecting on some issue or moment that has arisen in our readings or discussions (e.g., the problem with particular terms or some philosophical or practical dilemma). Ultimately, if offering a paragraph each week, honors students will have written roughly 15 reflective paragraphs for the semester. This must be emailed directly to me by Sunday 5pm each week.
\end{enumerate}

\hypertarget{student-accommodations}{%
\section{Student Accommodations}\label{student-accommodations}}

It is the University's goal that learning experiences be as accessible as possible. If you anticipate or experience physical or academic barriers based on disability or pregnancy, please let me know immediately so that we can discuss options. You are also welcome to contact Disability Resources (520-621-3268) to establish reasonable accommodations. For additional information on Disability Resources and reasonable accommodations, please visit \url{http://drc.arizona.edu/}.

\hypertarget{attendance-due-dates-and-missing-work}{%
\section{Attendance, Due Dates, and Missing Work}\label{attendance-due-dates-and-missing-work}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Missed class assignments or exams cannot be made up without a well-documented, verifiable, excuse (for example, a physician's medical excuse). Indeed, due dates are firm, and late work will be accepted only with a verifiable and valid excuse.
\item
  The UA policy regarding absences for any sincerely held religious belief, observance or practice will be accommodated where reasonable, \url{http://policy.arizona.edu/human-resources/religious-accommodation-policy}.
\item
  Absences pre-approved by the UA Dean of Students (or Dean designee) will be honored. \url{https://deanofstudents.arizona.edu/absences}\\
\item
  Arriving late and leaving early is extremely disruptive to others in the class. Please avoid this kind of disruption.
\item
  The UA's policy concerning Class Attendance and Administrative Drops is available at: \url{https://catalog.arizona.edu/policy/class-attendance-participation-and-administrative-drop}
\end{enumerate}

\hypertarget{course-conduct-and-campus-policies}{%
\section{Course Conduct and Campus Policies}\label{course-conduct-and-campus-policies}}

It's important to be familiar with all campus policies.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Students are encouraged to share intellectual views and discuss freely the principles and applications of course materials. However, graded work/exercises must be the product of independent effort unless otherwise instructed. Students are expected to adhere to the UA Code of Academic Integrity as described in the UA General Catalog. See: \url{http://deanofstudents.arizona.edu/academic-integrity/students/academic-integrity}.
\item
  It is the University's goal that learning experiences be as accessible as possible. If you anticipate or experience physical or academic barriers based on disability or pregnancy, please let me know immediately so that we can discuss options. You are also welcome to contact Disability Resources (520-621-3268) to establish reasonable accommodations. For additional information on Disability Resources and reasonable accommodations, please visit \url{http://drc.arizona.edu/}.
\item
  The UA Threatening Behavior by Students Policy prohibits threats of physical harm to any member of the University community, including to oneself. See \url{http://policy.arizona.edu/education-and-student-affairs/threatening-behavior-students}.
\item
  All student records will be managed and held confidentially. \url{http://www.registrar.arizona.edu/personal-information/family-educational-rights-and-privacy-act-1974-ferpa?topic=ferpa}
\item
  The University is committed to creating and maintaining an environment free of discrimination; see \url{http://policy.arizona.edu/human-resources/nondiscrimination-and-anti-harassment-policy}.
\item
  Information contained in this syllabus, other than the grade and absence policy, may be subject to change without advance notice as deemed appropriate by the instructor.
\end{enumerate}

\hypertarget{code-of-conduct}{%
\section{Code of Conduct}\label{code-of-conduct}}

This code of conduct is based on \href{https://docs.github.com/en/github/site-policy/github-community-guidelines}{GitHub Community Guidelines}. One of the goals of this course is to get you familiar with the data science community, and how people work and learn better together. This is a community we build together, and we need everybody's help to make it better each day.

\hypertarget{our-pledge}{%
\subsection{Our Pledge}\label{our-pledge}}

In the interest of fostering an open and welcoming environment, we as instructor and students pledge to making participation in our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.

\begin{itemize}
\item
  \textbf{Be welcoming and open-minded.} Although this is an intro course, like in any other learning setting, we have people at different levels of experience. Other people may not have the same experience level or background as you, but that doesn't mean they don't have good ideas to contribute. I encourage you to be welcoming to everyone, from more advanced coders to those just getting started. We can all learn from each other.
\item
  \textbf{Respect each other.} Nothing sabotages healthy conversation like rudeness. Be civil and professional, and don't post or say anything that a reasonable person would consider offensive, abusive, or hate speech. Don't harass or grief anyone. Treat each other with dignity and consideration in all interactions.
\end{itemize}

You may wish to respond to something by disagreeing with it. That's fine. But remember to criticize ideas, not people. Avoid name-calling, ad hominem attacks, responding to a post's tone instead of its actual content, and knee-jerk reactions. Instead, provide reasoned counter-arguments that improve the conversation.

\begin{itemize}
\item
  \textbf{Communicate with empathy.} Disagreements or differences of opinion are a fact of life. Being part of a community means interacting with people from a variety of backgrounds and perspectives (and we are all better because of this variety), many of which may not be your own. If you disagree with someone, try to understand and share their feelings before you address them. This will promote a respectful and friendly atmosphere where people feel comfortable asking questions, participating in discussions, and making contributions.
\item
  \textbf{Be clear and stay on topic.} The goal of this course is to learn about data science and how to do data science with R. Off-topic comments are a distraction (sometimes welcome, but usually not) from getting work done and being productive. Staying on topic helps produce positive and productive discussions.
\end{itemize}

Additionally, as this class will be conducted online, you might not have met each other in person. Communicating on the internet can be awkward, even when you already know people. It's hard to convey or read tone, and sarcasm is frequently misunderstood. Try to use clear language, and think about how it will be received by the other person.

\hypertarget{our-standards}{%
\subsection{Our Standards}\label{our-standards}}

Examples of behavior that contributes to creating a positive environment include:

\begin{itemize}
\item
  Using welcoming and inclusive language
\item
  Being respectful of differing viewpoints and experiences
\item
  Gracefully accepting constructive criticism
\item
  Focusing on what is best for the community
\item
  Showing empathy towards other community members
\end{itemize}

Examples of unacceptable behavior by participants include:

\begin{itemize}
\item
  The use of sexualized language or imagery and unwelcome sexual attention or advances
\item
  Trolling, insulting/derogatory comments, and personal or political attacks
\item
  Public or private harassment
\item
  Publishing others' private information, such as a physical or electronic address, without explicit permission
\item
  Other conduct which could reasonably be considered inappropriate in a professional setting
\end{itemize}

\hypertarget{enforcement}{%
\subsection{Enforcement}\label{enforcement}}

Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting your instructor at \href{mailto:adrianaps@email.arizona}{\nolinkurl{adrianaps@email.arizona}}. Your instructor will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. Your instructor is obligated to maintain confidentiality with regard to the reporter of an incident.

\hypertarget{attribution}{%
\subsection{Attribution}\label{attribution}}

This Code of Conduct is adapted from the \href{https://www.contributor-covenant.org/}{Contributor Covenant}, version 1.4, available at \url{http://contributor-covenant.org/version/1/4}

\hypertarget{how-to-ask-for-help}{%
\section{How to Ask For Help}\label{how-to-ask-for-help}}

We'll see in this course that a key skill that you should develop as a data science is the ability to find solutions to problems. Knowing how to get help is part of that skill.

\hypertarget{before-you-ask-for-help}{%
\subsection{Before You ask for help}\label{before-you-ask-for-help}}

\begin{itemize}
\item
  \textbf{Check for typos.} One of the most common causes of errors are typos, which usually throw an error such as {Error in \_\_\_\_\_ : could not find function ``\_\_\_\_\_''} due to a function being misspelled
\item
  \textbf{Check loaded packages.} You also get errors like {Error in data \%\textgreater\% summary() : could not find function ``\%\textgreater\%''} when you failed to load a package.
\item
  \textbf{Read the error message.} Don't ignore what R is telling you. Be aware that red text that appears in your console is not alwayws indication of errors. Sometimes it's just a warning.
\item
  \textbf{Google is your friend.} Copy and paste the exact error message on a Google search. (this step also includes \textbf{read the documentation} on the package you're trying to use).
\item
  If you are still stuck, you an always try \textbf{rubber duck debugging}. Describe the problem aloud, explaining it line-by-line, to a rubber duck or another person (who might not have any experience with programming of data science). This is also a good preparation step to asking other people for help (next section).
\end{itemize}

\hypertarget{ask-other-people-for-help}{%
\subsection{Ask other people for help}\label{ask-other-people-for-help}}

Like mentioned before, you should ask your peers for help before you ask your instructor. Relying on a single person to solve all of your problems is dangerous, because that person won't be available throughout your career as a data scientist.

\begin{itemize}
\item
  Check \href{https://ischool-esoc214.slack.com}{\textbf{our Slack}} to see if someone else has asked a question similar to yours, and whether there's a solution posted for it.
\item
  \textbf{Be precise and informative}. The more context you can provide about what you're trying to do and what errors you're getting, the better. Also describe the steps you took to try to solve the problem yourself.
\end{itemize}

\hypertarget{list-of-resources}{%
\subsection{List of Resources}\label{list-of-resources}}

\begin{itemize}
\tightlist
\item
  \href{https://www.r-project.org/help.html}{Getting Help with R}
\item
  \href{https://www.youtube.com/watch?v=ZFaWxxzouCY\&feature=youtu.be}{Roger Peng's How To Get Help video}
\item
  \href{https://rubberduckdebugging.com/}{Rubber Duck Debugging}
\end{itemize}

\hypertarget{whats_ds}{%
\chapter{What's data science?}\label{whats_ds}}

\hypertarget{before-class-1}{%
\section{Before class \#1}\label{before-class-1}}

Required external reading for this module: \href{readings/module2_what_is_data_science.pdf}{What's data science?} (4,660 words, approx. 20 minutes of reading time)

Watch the \href{https://youtu.be/6OFm7YcunWc?t=617}{YouTube video Angry Hiring Manager Panel} from 10:18 to 16:48 (6.5 minutes) and list the skills they mention as important to have in a data science position.

Fill out \href{https://forms.gle/NaqrC87cB8xh6Sdz8}{Survey 1} (10 min)

\hypertarget{whats-data-science}{%
\section{What's data science?}\label{whats-data-science}}

Data science is one of the fields with the highest demand, with prospects of increased demand for the next decade \citep{kross2020democratization, hadavand2018can}. Interestingly, the data scientist title was invented in 2008, and the median base salary for a data scientist surpassed \$100,000 in the United States in 2019 \citep{robinson_nolis_2020}.

\textbf{CHALLENGE}

Based on your own experience and on your reading for this module, in your groups discuss the following question:

\begin{itemize}
\tightlist
\item
  What is data science?
\end{itemize}

\hypertarget{what-does-a-data-scientist-do}{%
\section{What does a data scientist do?}\label{what-does-a-data-scientist-do}}

Data science is an interdisciplinary field, and as such data scientists hold jobs with a broad range of skills, from statistics to communication. \href{https://www.indeed.com/jobs?q=data+science\&l=United+States}{A quick search for data science jobs} reveals this long list of skills. However, no single data scientist has all skills listed for different data science jobs. Instead, each data scientist specializes in different skills \citep{robinson_nolis_2020}.

\textbf{CHALLENGE}

Make a list of skills listed on data science job announcements and in the video you just watched. Based on these, discuss the following questions in your group:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Which skills do you already have? At what level of proficiency?
\item
  Which skills are you interested in developing further?
\item
  Based on the skills you already have, and the skills you want to acquire, what type of job in data science would you be interested in?
\end{enumerate}

\hypertarget{data-science-workflow}{%
\section{Data Science Workflow}\label{data-science-workflow}}

The basic data science workflow involve three main parts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  The Question: Form the question you want to answer. Many times you will be given a question, and you have to ``translate'' it so you can answer it with your data analysis.
\item
  Data Acquisition: data file, database, or web API
\item
  Data Wrangling: import + tidy data + transform \citep{grolemund2018r}
\item
  Data Exploration: transform + visualize + model + repeat \citep{grolemund2018r}
\item
  Results Communication: visualize + write + knit \citep{grolemund2018r}
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/data-science} 

}

\caption{typical data science project model (Grolemund and Wickham, 2018)}\label{fig:unnamed-chunk-3}
\end{figure}

\textbf{CHALLENGE}

In your groups, based on your own intuition and experience, and based on the \href{https://r4ds.had.co.nz/introduction.html}{Introduction to R for Data Science} book \citep{grolemund2018r}, summarize what each of the following steps means:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Tidy
\item
  Transform
\item
  Visualize
\item
  Model
\item
  Communicate
\end{enumerate}

We will approach the entire data science workflow in this course (but not necessarily every step listed), not in this order. We start with step 3 (Data Wrangling) and 4 (Data Exploration), before we address step 2 (Data Acquisition) and step 5 (Communication)

\textbf{CHALLENGE}

Go back to the list of skills and job positions we discussed (based on the reading and the video):

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Which steps in the data science workflow correspond to the job skills we talked about?
\end{enumerate}

\hypertarget{before-class-2}{%
\section{Before class \#2}\label{before-class-2}}

Please fill out \href{https://forms.gle/NaqrC87cB8xh6Sdz8}{Survey 1} (10 min).

Reading: \href{readings/module2_eds_leek_whatsdatascience.pdf}{Data Science examples} (1,0333 words, 8 min)

Reading: \href{readings/module2_modern_data_science_data_intake.pdf}{Data Intake} (1,686 words, 12 min)

\hypertarget{whats-data}{%
\section{What's data?}\label{whats-data}}

\textbf{CHALLENGE}

In your small group, discuss the examples provided in the excerpt from ``Executive Data Science'' \citep{caffo2016executive}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Is data science about ``data''? Why or why not?
\item
  Why did Netflix end up not implementing the best solution from the Netflix prize challenge?
\item
  What data was used in each of the examples provided in the reading?
\item
  What is data? (come up with a definition).
\end{enumerate}

~

Examples of what data might look like.

\begin{itemize}
\tightlist
\item
  Structured data (rare):
\end{itemize}

\begin{tabular}{l|l|r}
\hline
State & School Year & Average Tuition\\
\hline
Nevada & 2004-05 & 3621.392\\
\hline
Nevada & 2005-06 & 3687.290\\
\hline
Florida & 2004-05 & 3848.201\\
\hline
Florida & 2007-08 & 3879.416\\
\hline
Florida & 2006-07 & 3887.656\\
\hline
Florida & 2005-06 & 3924.234\\
\hline
Wyoming & 2008-09 & 3928.671\\
\hline
Wyoming & 2007-08 & 4071.898\\
\hline
Wyoming & 2004-05 & 4086.351\\
\hline
Wyoming & 2006-07 & 4122.205\\
\hline
\end{tabular}

\textbf{CHALLENGE}

Which of the columns (or variables) in the data frame above are \textbf{categorical}, which are \textbf{quantitative}?

~

\begin{itemize}
\tightlist
\item
  Structured, but messy data (more common):
\end{itemize}

\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
State & 2004-05 & 2005-06 & 2006-07 & 2007-08 & 2008-09 & 2009-10 & 2010-11 & 2011-12 & 2012-13 & 2013-14 & 2014-15 & 2015-16\\
\hline
Alabama & 5682.838 & 5840.550 & 5753.496 & 6008.169 & 6475.092 & 7188.954 & 8071.134 & 8451.902 & 9098.069 & 9358.929 & 9496.084 & 9751.101\\
\hline
Alaska & 4328.281 & 4632.623 & 4918.501 & 5069.822 & 5075.482 & 5454.607 & 5759.153 & 5762.421 & 6026.143 & 6012.445 & 6148.808 & 6571.340\\
\hline
Arizona & 5138.495 & 5415.516 & 5481.419 & 5681.638 & 6058.464 & 7263.204 & 8839.605 & 9966.716 & 10133.503 & 10296.200 & 10413.844 & 10646.278\\
\hline
Arkansas & 5772.302 & 6082.379 & 6231.977 & 6414.900 & 6416.503 & 6627.092 & 6900.912 & 7028.991 & 7286.580 & 7408.495 & 7606.410 & 7867.297\\
\hline
California & 5285.921 & 5527.881 & 5334.826 & 5672.472 & 5897.888 & 7258.771 & 8193.739 & 9436.426 & 9360.574 & 9274.193 & 9186.824 & 9269.844\\
\hline
Colorado & 4703.777 & 5406.967 & 5596.348 & 6227.002 & 6284.137 & 6948.473 & 7748.201 & 8315.632 & 8792.856 & 9292.954 & 9298.599 & 9748.188\\
\hline
Connecticut & 7983.695 & 8249.074 & 8367.549 & 8677.702 & 8720.976 & 9371.019 & 9827.013 & 9736.431 & 10036.627 & 10453.110 & 10663.995 & 11397.337\\
\hline
Delaware & 8352.890 & 8610.597 & 8681.846 & 8945.801 & 8995.473 & 9987.183 & 10534.181 & 11026.241 & 11362.690 & 11502.524 & 11514.660 & 11676.216\\
\hline
Florida & 3848.201 & 3924.234 & 3887.656 & 3879.416 & 4150.004 & 4783.032 & 5510.659 & 5940.945 & 6494.901 & 6451.664 & 6345.000 & 6360.159\\
\hline
Georgia & 4298.040 & 4492.167 & 4584.268 & 4790.266 & 4831.365 & 5549.913 & 6428.007 & 7709.284 & 7853.257 & 7992.390 & 8063.014 & 8446.961\\
\hline
\end{tabular}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{tabular}{r|l|l|l}
\hline
user\_id & screen\_name & text & reply\_to\_screen\_name\\
\hline
6.331283e+07 & blagogirl & @realTuckFrumper The illiterate calling Iran out?
80 million bounty on Trumps head? & realTuckFrumper\\
\hline
6.331283e+07 & blagogirl & @JonHutson Iran does NOT fear Trump. 
They realize what OUR country is dealing with. 
"The White House is inflicted with mental retardation" & JonHutson\\
\hline
1.125104e+18 & dl\_kirkwood & I'm afraid 11 soldiers had to be shipped out from the Iran hit after all with traumatic brain injuries. Seems the Military does not notify homeland unless a soldiers is shipped out for the injury. So, Trump did not know for a week. https://t.co/HdBNbKClBl & NA\\
\hline
2.820552e+07 & djbarro & @GloriaAllred Are you going to carry a sign supporting the women in Iran brave enough to remove their hijabs and go to prison? & GloriaAllred\\
\hline
1.506314e+08 & kizu91 & US...Special...Representative...Hold...Press...Briefing...Situation in...Iran...Video...first...week...January...saw...drastic...spike...tensions...Washington...Tehran...President...Donald Trump...order...assassination...elite...Quds...Force...commander...Qasem...Soleimani...Iraq & NA\\
\hline
1.506314e+08 & kizu91 & crash...land...collide...plane...aircraft...all...176...people...on board...Iran...missile...attack...US...base...Iraq...rocket...Western...Sahara...Suriname...Colombia...Dominica...Australia...Anguilla...Guadeloupe...Uruguay...Cyprus...Namibia...Brazil...Paraguay...Denmark...55 & NA\\
\hline
1.506314e+08 & kizu91 & Iran...MP...Urge...Gov't...Expel...UK...Envoy...Consider...Downgrading...Diplomatic...Ties...Alleged...Meddling...envoy...Robert Macaire...detained...days...ago...alleged...participation...unsanctioned...protest...Tehran...down...Ukraine...Boeing...737...release...15...minutes & NA\\
\hline
1.506314e+08 & kizu91 & Government...Supporter...Gather...Tehran...13....Friday...Prayer...Video...Iran...gather...rally...commemorate...kill...fatal...crash...land...collide...Ukraine...Boeing...plane...aircraft...shot...down...missile...rocket...January...Imam...Khomeini...International...Airport...16 & NA\\
\hline
1.506314e+08 & kizu91 & British...Treasury...Expand...Hezbollah...Asset...Freeze...UK...government...approved...measure...follow...heat...conflict...United States...Islamic...Republic...Iran...Trump...Administration...target...assassination...high-profile...military...general...early...January...film & NA\\
\hline
7.297365e+17 & SwmpladySH & Hackers Are Coming for the 2020 Election — And We’re Not Ready https://t.co/q82kNu9gMd via @RollingStone & NA\\
\hline
\end{tabular}

\begin{itemize}
\tightlist
\item
  Textual Data (always messy):
\end{itemize}

\begin{verbatim}
##  [1] "CHAPTER I"                                                               
##  [2] ""                                                                        
##  [3] ""                                                                        
##  [4] "Emma Woodhouse, handsome, clever, and rich, with a comfortable home"     
##  [5] "and happy disposition, seemed to unite some of the best blessings of"    
##  [6] "existence; and had lived nearly twenty-one years in the world with very" 
##  [7] "little to distress or vex her."                                          
##  [8] ""                                                                        
##  [9] "She was the youngest of the two daughters of a most affectionate,"       
## [10] "indulgent father; and had, in consequence of her sister's marriage, been"
\end{verbatim}

** CHALLENGE **

What data formats are out there in the world. Create a list based on your experience and the excerpt from ``Modern Data Science with R'' \citep{baumer2017modern}.

\hypertarget{what-does-data-analysis-look-like}{%
\section{What does data analysis look like?}\label{what-does-data-analysis-look-like}}

The way you communicate your data analysis will depend on what question you're trying to answer and who your audience is. Here are some of my favorite data analysis reports:

\begin{itemize}
\item
  \href{https://twitter.com/IsChiaThere/status/1282681472185401349/photo/1}{Whose (coffee) beans reign supreme?} A \#tidytuesday static image
\item
  \href{https://twitter.com/geokaramanis/status/1283410776913514496/photo/1}{Women in Space} A \#tidytuesday static image
\item
  \href{https://sebastianwolf.shinyapps.io/stravachaserapp/}{Which city is faster?} A City Cycle Race Shinny app
\item
  \href{https://pudding.cool/2020/07/gendered-descriptions/}{The Physical Traits that Define Men and Women in Literature} An interactice website
\end{itemize}

\hypertarget{install-r}{%
\chapter{Exploring our IDE (Rstudio)}\label{install-r}}

\hypertarget{before-class-3}{%
\section{Before class \#3}\label{before-class-3}}

Install R and RStudio.

We are using RStudio as our IDE for this course. If you are running your R code in your computer, you need to install both R and RStudio. Alternatively, you can create a free account at \url{http://rstudio.cloud} and run your R code in the cloud. Either way, we will be using the same IDE (i.e., RStudio).

What's an \textbf{IDE}? IDE stands for \textbf{i}ntegrated \textbf{d}evelopment \textbf{e}nvironment, and its goal is to facilitate coding by integrating a \textbf{text editor}, a \textbf{console} and other tools into one window.

\hypertarget{ive-never-installed-r-and-rstudio-in-my-computer-or-im-not-sure-i-have-r-and-rstudio-installed-in-my-computer}{%
\subsection{I've never installed R and RStudio in my computer OR I'm not sure I have R and RStudio installed in my computer}\label{ive-never-installed-r-and-rstudio-in-my-computer-or-im-not-sure-i-have-r-and-rstudio-installed-in-my-computer}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Download and install R from \url{https://cran.r-project.org} (If you are a Windows user, first \href{https://www.computerhope.com/issues/ch001121.htm\#:~:text=Press\%20and\%20hold\%20the\%20Windows,running\%20the\%2064\%2Dbit\%20version.}{determine if you are running the 32 or the 64 bit version})
\item
  Download and install RStudio from \url{https://rstudio.com/products/rstudio/download/\#download}
\end{enumerate}

Here's a \href{https://youtu.be/Iwp8bm7w4fQ}{video on how to install R and RStudio on a mac}.

\hypertarget{i-already-have-r-and-rstudio-installed}{%
\subsection{I already have R and RStudio installed}\label{i-already-have-r-and-rstudio-installed}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Open RStudio
\item
  Check your R version by entering \texttt{sessionInfo()} on your console.
\item
  The latest release for R was June 22, 2020 (R version 4.0.2 Taking Off Again). If your R version is older than the most recent version, please follow step 1 in the previous section to update R.
\item
  Check your RStudio version, if your version is older than Version 1.3.x, please follow step 2 in the previous section to update RStudio.
\end{enumerate}

How often should I update R and RStudio? Always make sure that you have the latest version of R, RStudio, and the packages you're using in your code to ensure you are not running into bugs that are caused by having older versions installed in your computer.

When \href{https://community.rstudio.com/t/should-i-update-all-my-r-packages-frequently-yes-no-why/5856/4}{asked}, \href{https://community.rstudio.com/u/jennybryan}{Jenny Bryan} summarizes the importance of keeping your system up-to-date saying that ``You will always eventually have a reason that you must update. So you can either do that very infrequently, suffer with old versions in the middle, and experience great pain at update. Or admit that maintaining your system is a normal ongoing activity, and do it more often.''

~

You can ensure your packages are also up-to-date by clicking on ``Tools'' on your RStudio top menu bar, and selecting ``Check for Packages Updates\ldots{}''

\hypertarget{why-learn-r}{%
\section{Why learn R?}\label{why-learn-r}}

R is both a programming language and \href{https://www.r-project.org/}{a free software environment for statistical computing and graphics}. In addition to being free, here are other reasons to learn R:

\begin{itemize}
\item
  \textbf{R is popular.} According to \href{http://r4stats.com/articles/popularity/}{Robert A. Muenchen's post on the popularity of data science software} (which is updated frequently), R is among the top 5 technologies that are mentioned in data science job ads on indeed.com.
\item
  \textbf{R is very powerful and versatile}. From creating websites (like this bookdown you're reading right now) to building machine learning models, R has it all.
\item
  \textbf{The R community is active and very supportive}. Because R is so popular, there are a number of forums on R. A good way to get a glimpse on how active the R community is to follow \href{https://twitter.com/search?q=\%23rstats}{\texttt{\#rstats}} on twitter.
\end{itemize}

\hypertarget{why-use-rstudio}{%
\section{Why use RStudio?}\label{why-use-rstudio}}

You can just use R, but RStudio is an IDE that makes using R easier and more fun. Some features that make RStudio the IDE that many data scientists use:

\begin{itemize}
\item
  RStudio is \textbf{free} and \textbf{open source}.
\item
  RStudio contains a full-feature integrated text editor, with tab-completion, spellcheck, etc.
\item
  RStudio is a cross-platform interface that looks the same across platforms.
\item
  RStudio allows you to organize your data science projects so you're not always hunting for the right script that goes with the data you want to analyze. (also, it integrates nicely with \texttt{rmarkdown} and \texttt{knitr})
\end{itemize}

\hypertarget{create-an-r-project}{%
\section{Create an R Project}\label{create-an-r-project}}

In today's class, we will focus on situating ourselves around our IDE. For every lesson, we will either start a new R project or open an R project we've been working on.

Why create a RStudio project? RStudio projects make it easier to keep your projects organized, since each project has their own working directory, workspace, history, and source documents. In other words, it's much easier to open an R project and not have to worry about setting your working directory than to try to hunt down your files.

Here are the steps we are starting with today:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start a new R project
\item
  Create a new R script
\item
  Save that R script as 01-class\_one
\end{enumerate}

~

\textbf{CHALLENGE}

Take a moment to look around your IDE. What are the main panes on the RStudio interface. What are the 4 main areas of the interface? Can you guess what each area is for?

\hypertarget{operations-and-objects}{%
\section{Operations and Objects}\label{operations-and-objects}}

Let's start by using R as a calculator. On your \textbf{console} type \texttt{3\ +\ 3} and hit enter.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{3} \OperatorTok{+}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

What symbols do we use for all basic operations (addition, subtraction, multiplication, and division)?
What happens if you type \texttt{3\ +}?

Let's save our calculation into an object, by using the assignment symbol \texttt{\textless{}-}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sum_result <-}\StringTok{ }\DecValTok{3} \OperatorTok{+}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

Take a moment to look around your IDE once again. What has changed?

Now, let's use this new object in our calculation

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sum_result }\OperatorTok{+}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9
\end{verbatim}

Take a moment to look around your IDE once again. Has anything changed?

What else can we do with an object?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(sum_result)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

R is primarily a functional programming language. That means that there pre-programmed functions in base R such as \texttt{class()} and that you can also write your own functions (more on that later).

Type \texttt{?class} in your console and hit enter to get more information about this function.

\textbf{CHALLENGE}

Create an object called \texttt{daisys\_age} that holds the number 8.
Multiply \texttt{daisys\_age} by 4 and save the results in another object called \texttt{daisys\_human\_age}

Imagine I had multiple pets (unfortunately, that is not true, Daisy is my only pet). I can create a \textbf{vector} to hold multiple numbers representing the age of each of my pets.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets_ages <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Take a moment to look around your IDE once again. What has changed?

What is the class of the object \texttt{my\_pets\_ages}?

Now let's multiply this vector by 4.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets_ages }\OperatorTok{*}\StringTok{ }\DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 32  8 24 12  4
\end{verbatim}

Errors are pretty common when writing code in any programming language, so be ready to read error messages and debug your code. Let's insert a typing error in our previous code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets_ages <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\StringTok{'3'}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{CHALLENGE}

Try to multiply \texttt{my\_pets\_ages} by 4. What happens? How can we debug our code to find out what is causing the error?

\hypertarget{r-basics}{%
\chapter{R Basics}\label{r-basics}}

\hypertarget{before-class-4}{%
\section{Before Class \#4}\label{before-class-4}}

Read \href{http://varianceexplained.org/programming/bad-code/}{A Million Lines of Bad Code} a blog post by \href{http://varianceexplained.org/about/}{David Robinson}. (549 words, 5 minutes)

Read \href{readings/module7_eds_whats_stats.pdf}{What is Statistics Good For?} (398 words, 3 min)

\hypertarget{dataframes}{%
\section{Dataframes}\label{dataframes}}

You will rarely work with individual numeric values, or even individual numeric vectors. Often, we have information organized in dataframes, which is R's version of a spreadsheet.

Let's go back to my imaginary pet's ages (make sure you have the correct vector in your global environment).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets_ages <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\StringTok{'3'}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{my_pets_ages <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(my_pets_ages)}
\end{Highlighting}
\end{Shaded}

We will now create a vector of strings or characters that holds my imaginary pets' names (we have to be careful to keep the same order then the \texttt{my\_pets\_ages} vector).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets_names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'Daisy'}\NormalTok{, }\StringTok{'Violet'}\NormalTok{, }\StringTok{'Lily'}\NormalTok{, }\StringTok{'Iris'}\NormalTok{, }\StringTok{'Poppy'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's now create a dataframe that contains info about my pets.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create dataframe}
\NormalTok{my_pets <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{name =}\NormalTok{ my_pets_names, }\DataTypeTok{age =}\NormalTok{ my_pets_ages)}

\CommentTok{# print out dataframe}
\NormalTok{my_pets}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     name age
## 1  Daisy   8
## 2 Violet   2
## 3   Lily   6
## 4   Iris   3
## 5  Poppy   1
\end{verbatim}

\textbf{CHALLENGE}

There's a number of functions you can run on dataframes. Try running the following functions on \texttt{my\_pets}:

\begin{itemize}
\item
  summary()
\item
  nrow()
\item
  ncol()
\item
  dim()
\end{itemize}

What other functions can/do you think/know of?

\hypertarget{slicing-your-dataframe}{%
\section{Slicing your dataframe}\label{slicing-your-dataframe}}

There are different ways you can slice or subset your dataframe.

You can use indices for rows and columns.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[}\DecValTok{1}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    name age
## 1 Daisy   8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Daisy"  "Violet" "Lily"   "Iris"   "Poppy"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Daisy"
\end{verbatim}

You can use a column name or a row name instead of an index.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[, }\StringTok{'age'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8 2 6 3 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[}\StringTok{'1'}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    name age
## 1 Daisy   8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[}\StringTok{'1'}\NormalTok{, }\StringTok{'age'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8
\end{verbatim}

Or you can use \texttt{\$} to retrieve values from a column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets}\OperatorTok{$}\NormalTok{age}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8 2 6 3 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets}\OperatorTok{$}\NormalTok{age[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8
\end{verbatim}

You can also use comparisons to filter your dataframe

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get index with which() function}
\KeywordTok{which}\NormalTok{(my_pets}\OperatorTok{$}\NormalTok{age }\OperatorTok{==}\StringTok{ }\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# use which() inside dataframe indexing my_pets[row_number, column_number]}
\NormalTok{my_pets[}\KeywordTok{which}\NormalTok{(my_pets}\OperatorTok{$}\NormalTok{age }\OperatorTok{==}\StringTok{ }\DecValTok{8}\NormalTok{),]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    name age
## 1 Daisy   8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[}\KeywordTok{which}\NormalTok{(my_pets}\OperatorTok{$}\NormalTok{age }\OperatorTok{==}\StringTok{ }\DecValTok{8}\NormalTok{), }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Daisy"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[}\KeywordTok{which}\NormalTok{(my_pets}\OperatorTok{$}\NormalTok{age }\OperatorTok{==}\StringTok{ }\DecValTok{8}\NormalTok{), }\StringTok{'name'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Daisy"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pets[}\KeywordTok{which}\NormalTok{(my_pets}\OperatorTok{$}\NormalTok{age }\OperatorTok{==}\StringTok{ }\DecValTok{8}\NormalTok{),]}\OperatorTok{$}\NormalTok{name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Daisy"
\end{verbatim}

\textbf{CHALLENGE}

Print out a list of pet names that are older than 3.

\hypertarget{adding-new-variables-i.e.-columns-to-your-dataframe}{%
\section{Adding new variables (i.e., columns) to your dataframe}\label{adding-new-variables-i.e.-columns-to-your-dataframe}}

So far the \texttt{my\_pets} dataframe has two columns: name and age.

Let's add a third column with the pets' ages in human years. For that, we are going to use \texttt{\$} on with a variable (or column) name that does not exist in our dataframe yet. We will then assign to this variable the value in the \texttt{age} column multiplied by 4.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create new column called human_years}
\NormalTok{my_pets}\OperatorTok{$}\NormalTok{human_years <-}\StringTok{ }\NormalTok{my_pets}\OperatorTok{$}\NormalTok{age }\OperatorTok{*}\StringTok{ }\DecValTok{4}

\CommentTok{# print dataframe}
\NormalTok{my_pets}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     name age human_years
## 1  Daisy   8          32
## 2 Violet   2           8
## 3   Lily   6          24
## 4   Iris   3          12
## 5  Poppy   1           4
\end{verbatim}

Inspect the new \texttt{my\_pets} dataframe. What dimensions does it have now? How could you get a list of just the human years values in the data frame?

\hypertarget{descriptive-stats-on-dataframes}{%
\section{Descriptive stats on dataframes}\label{descriptive-stats-on-dataframes}}

Let's explore some functions for descriptive statistics.

\textbf{CHALLENGE}

Try running the following functions on \texttt{my\_pets\$age} and \texttt{my\_pets\$human\_years}:

\begin{itemize}
\item
  mean()
\item
  sd()
\item
  median()
\item
  max()
\item
  min()
\item
  range()
\end{itemize}

What other functions can/do you think/know of?

\hypertarget{note-on-coding-style}{%
\section{Note on coding style}\label{note-on-coding-style}}

Coding style refers to how you name your objects and functions, how you comment your code, how you use spacing throughout your code, etc. If your coding style is consistent, your code is easier to read and easier to debug as a result. Here's some guides, so you can develop your own coding style:

\begin{itemize}
\item
  \href{https://style.tidyverse.org}{The tidyverse style guide}
\item
  \href{http://adv-r.had.co.nz/Style.html}{Hadley Wickham's Advance R coding style}
\item
  \href{https://google.github.io/styleguide/Rguide.html}{Google's R Style Guide}
\end{itemize}

\hypertarget{version-control}{%
\chapter{Version Control}\label{version-control}}

\hypertarget{before-class-5}{%
\section{Before Class \#5}\label{before-class-5}}

\hypertarget{install-git-on-your-computer}{%
\subsection{Install git on your computer}\label{install-git-on-your-computer}}

Access the \href{https://git-scm.com/download}{git download page} and download the appropriate version for your machine.

If you have a Windows 10 machine, you can watch \href{https://www.youtube.com/watch?v=nbFwejIsHlY}{this video that shows you how to install Git on windows}. When installing, note where it's installed (on the ``Select Destination Location'' window) so you can check if you have the correct path to Git set up in RStudio (it's usually \texttt{C:\textbackslash{}Program\textbackslash{}Git}).

If you have a Mac, you can watch \href{https://www.youtube.com/watch?v=PSULlxUk744}{this video that shows you how to install Git on a Mac}.

\hypertarget{create-a-github-account}{%
\subsection{Create a GitHub account}\label{create-a-github-account}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Access the \href{https://github.com/}{GitHub} page.
\item
  Click on ``\href{https://github.com/join}{Sign Up for GitHub}.''
\item
  Fill out the ``Create your account'' forms.
\item
  A verification will be sent to your email address, check your inbox for a ``Please verify your email address'' message. Click on ``Verify email address'' button.
\end{enumerate}

If you already have a GitHub account, confirm you know your username and password by logging in at \href{https://github.com/}{GitHub}.

\hypertarget{join-our-github-classroom}{%
\subsection{Join our GitHub classroom}\label{join-our-github-classroom}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Access our \href{https://classroom.github.com/classrooms/69162822-esoc214-classroom-1}{join our GitHub classroom} page.
\item
  A window with information about what GitHub Classroom wants to access from your GitHub profile will appear. Click on ``Authorize github''.
\item
  Access our \href{https://classroom.github.com/a/uE1b8ho7}{first assignment} and click on ``Accept this assignment''
\end{enumerate}

\hypertarget{link-rstudio-to-github}{%
\subsection{Link RStudio to GitHub}\label{link-rstudio-to-github}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open ``preferences'' in RStudio.
\item
  Click on ``Git/SVN'' in the menu on the left.
\item
  Under ``SSH RSA Key:'' click on ``Create RSA Key\ldots{}''
\item
  A window will pop up, click on ``Create''
\item
  A new window will pop up, click ``Close''
\item
  Now there's a ``View public key'' link next to ``SSH RSA Key:''; click on it
\item
  Copy key and close the window
\item
  Go to your \href{https://github.com/settings/profile}{GitHub account settings}
\item
  On the menu on the left, click on ``SSH and GPC keys''
\item
  Click on the ``New SSH Key'' button
\item
  Choose a title (e.g., RStudio Connection) and copy the key to the ``key'' field
\item
  Click ``Add SSH Key''
\end{enumerate}

\hypertarget{what-is-version-control}{%
\section{What is version control?}\label{what-is-version-control}}

Version control is a best practice for reproducible analyses, and widely used in industry and research (i.e., you will need to know how to use version control in your future job).

The purpose of version control is to keep track of changes to your files over time, so that you can recall specific versions at any point in your project.

\href{https://git-scm.com/}{Git} is an open source version control software system that is very popular -- 58\% of data scientist use Git \citep{beckman2020implementing}. There are a number of other version control software available (e.g., \href{https://www.perforce.com/blog/vcs/git-vs-perforce-how-choose-and-when-use-both}{Perforce}).

\hypertarget{submitting-assignments}{%
\section{Submitting assignments}\label{submitting-assignments}}

\hypertarget{clone-assignment-repository}{%
\subsection{Clone assignment repository}\label{clone-assignment-repository}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to our \href{https://classroom.github.com/a/uE1b8ho7}{first assignment GitHub repository}
\item
  Click on the ``Code'' button and copy the git url (e.g., \url{https://github.com/esoc214/test-assignment-yournamehere.git})
\item
  Open RStudio
\item
  Go ``File'' \textgreater{} ``New Project\ldots{}''
\item
  In the pop-up window, select ``Version Control''
\item
  Then choose ``Git''
\item
  In the ``Repository URL:'' field enter the link to the first assignment repository from your GitHub account.
\item
  Click ``Create''
\end{enumerate}

\hypertarget{modify-files}{%
\subsection{Modify files}\label{modify-files}}

For the first assignment, which is a test assignment so you're all set up to submitting all of your assignments for this class, you need to modify \texttt{READM.md} only. For other assignments you will need to edit .R scripts.

\hypertarget{commit-changes}{%
\subsection{Commit changes}\label{commit-changes}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  On the top right panel in RStudio (i.e., Environment quadrant), click on the ``Git'' tab
\item
  You will see a list of files, indicating which files have been modified (a blue ``M'' shows next to modified file).
\item
  Click on ``Commit'' on the top of this tab
\item
  A new window will pop-up. Stage the files you want to commit (click on the check box next to file) and enter a commit message.
\item
  Press ``Commit'' and if everything looks good, close the commit window.
\item
  Click ``Push'' on top right
\end{enumerate}

\hypertarget{intro-to-tidyverse}{%
\chapter{Intro to Tidyverse}\label{intro-to-tidyverse}}

\hypertarget{before-class-6}{%
\section{Before Class \#6}\label{before-class-6}}

Read \href{https://www.r-bloggers.com/advice-to-young-and-old-programmers-a-conversation-with-hadley-wickham/}{Advice to Young (and Old) Programmers: A Conversation with Hadley Wickham} by Philip Waggoner (2,599 words, 10 minutes)

\hypertarget{what-are-r-packages}{%
\section{What are R Packages?}\label{what-are-r-packages}}

An R package contains functions, and it might contain data. There are a lot of R packages out here (check the Comprehensive R Archive Network, i.e., CRAN, for a \href{https://cran.r-project.org/web/packages/available_packages_by_name.html}{full list}). That is one of the beautiful things about R, anyone can create an R package to share their code.

\hypertarget{installing-packages}{%
\section{Installing Packages}\label{installing-packages}}

The function to install packages in R is \texttt{install.packages()}. We will be working with \href{https://www.tidyverse.org/}{TidyVerse} extensively in this course, which is a collection of R packages carefully designed for data science.

Open your RStudio. In your console, enter the following to install tidyverse (this may take a while).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"tidyverse"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You need to install any package only once (remember to check for new package versions and to keep your packages updated). However, with every new R session, you need to load the packages you are going to use by using the \texttt{library()} function (a library is an installed R package in your computer).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Note that when calling the \texttt{install.packages()} function you need to enter the package name between quotation marks (e.g., ``tidyverse''). When you call the \texttt{library()} function, you don't use quotation marks (e.g., tidyverse).

\hypertarget{before-you-load-your-data}{%
\section{Before You Load your Data}\label{before-you-load-your-data}}

Although we are working within an R project, which sets the working directory automatically for you, it's good practice to check what folder you are working from by calling the \texttt{getwd()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "/Users/adriana/Desktop/ESOC214/Fall 2020/bookdown/ESOC_214_Fall_2020"
\end{verbatim}

You can list the contents of your working directory by using the \texttt{dir()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dir}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

We are going to create a \texttt{data} folder in our project, to keep things organized. Today we will be working with \href{https://www.kaggle.com/groundhogclub/groundhog-day}{a data set that contains groundhog day forecasts and temperature}. I cleaned up this data set already (no need for data tidying for now).

You can now list the contents of your \texttt{data} folder with the \texttt{dir()} function with a string that specifies the folder as a parameter.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dir}\NormalTok{(}\StringTok{"data"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "clean_beer_awards.csv"                
##  [2] "elnino.csv"                           
##  [3] "GlobalLandTemperaturesByCountry.csv"  
##  [4] "GlobalLandTemperaturesByMajorCity.csv"
##  [5] "groundhog_day.csv"                    
##  [6] "nfl_salary.xlsx"                      
##  [7] "olympic_history_athlete_events.csv"   
##  [8] "olympic_history_noc_regions.csv"      
##  [9] "passwords.csv"                        
## [10] "president_county_candidate.csv"       
## [11] "spotify_songs_clean.csv"              
## [12] "spotify_songs.csv"                    
## [13] "tweets.tsv"                           
## [14] "us_avg_tuition.xlsx"                  
## [15] "women_in_labor_force.csv"
\end{verbatim}

\hypertarget{whats-our-question-again}{%
\section{What's our question again?}\label{whats-our-question-again}}

Here's what we will focus on answering today, which is an excerpt from the \href{https://www.kaggle.com/groundhogclub/groundhog-day}{Groundhog Day Forecasts and Temperatures} kaggle page.

``Thousands gather at Gobbler's Knob in Punxsutawney, Pennsylvania, on the second day of February to await the spring forecast from a groundhog known as Punxsutawney Phil. According to legend, if Phil sees his shadow the United States is in store for six more weeks of winter weather. But, if Phil doesn't see his shadow, the country should expect warmer temperatures and the arrival of an early spring.''

So, in summary, our question is \textbf{How accurate is Punxsutawney Phil's winter weather forecast?}

\hypertarget{load-data-with-tidyverse}{%
\section{Load Data with Tidyverse}\label{load-data-with-tidyverse}}

We will use the \texttt{read\_csv()} function from the \texttt{readr} package (which is part of \texttt{tidyverse}) to read data in. Be careful, there's a similar function that is read.csv() from base R. We do want to use the function with the \texttt{\_} (i.e., \texttt{read\_csv()})

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/groundhog_day.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   Year = col_double(),
##   Punxsutawney_Phil = col_character(),
##   February_Average_Temperature = col_double(),
##   February_Average_Temperature_Northeast = col_double(),
##   February_Average_Temperature_Midwest = col_double(),
##   February_Average_Temperature_Pennsylvania = col_double(),
##   March_Average_Temperature = col_double(),
##   March_Average_Temperature_Northeast = col_double(),
##   March_Average_Temperature_Midwest = col_double(),
##   March_Average_Temperature_Pennsylvania = col_double()
## )
\end{verbatim}

\textbf{CHALLENGE}

\textbf{Reading warnings} - R often prints out warnings in red (these are not always errors). What information did you get when loading your data?

\hypertarget{inspect-your-data}{%
\section{Inspect Your Data}\label{inspect-your-data}}

As with any other programming language, there are multiple ways to doing anything. As such, there are multiple ways of inspecting your data in R. Here are some of my favorite ways of inspecting my data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get an overview of the data frame}
\KeywordTok{glimpse}\NormalTok{(groundhog_predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 122
## Columns: 10
## $ Year                                      <dbl> 1895, 1896, 1897, 1898, 1...
## $ Punxsutawney_Phil                         <chr> "No Record", "No Record",...
## $ February_Average_Temperature              <dbl> 26.60, 35.04, 33.39, 35.3...
## $ February_Average_Temperature_Northeast    <dbl> 15.6, 22.2, 23.6, 24.8, 1...
## $ February_Average_Temperature_Midwest      <dbl> 21.9, 33.5, 34.7, 33.3, 2...
## $ February_Average_Temperature_Pennsylvania <dbl> 17.0, 26.6, 27.9, 26.7, 2...
## $ March_Average_Temperature                 <dbl> 39.97, 38.03, 38.79, 41.0...
## $ March_Average_Temperature_Northeast       <dbl> 27.6, 25.3, 32.0, 38.0, 2...
## $ March_Average_Temperature_Midwest         <dbl> 40.2, 36.9, 44.0, 46.0, 3...
## $ March_Average_Temperature_Pennsylvania    <dbl> 31.3, 27.8, 36.9, 42.0, 3...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(groundhog_predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Year      Punxsutawney_Phil  February_Average_Temperature
##  Min.   :1895   Length:122         Min.   :25.23               
##  1st Qu.:1925   Class :character   1st Qu.:31.78               
##  Median :1956   Mode  :character   Median :33.69               
##  Mean   :1956                      Mean   :33.80               
##  3rd Qu.:1986                      3rd Qu.:36.01               
##  Max.   :2016                      Max.   :41.41               
##  February_Average_Temperature_Northeast February_Average_Temperature_Midwest
##  Min.   :10.40                          Min.   :20.30                       
##  1st Qu.:20.02                          1st Qu.:29.62                       
##  Median :22.95                          Median :33.20                       
##  Mean   :22.69                          Mean   :32.69                       
##  3rd Qu.:25.98                          3rd Qu.:36.30                       
##  Max.   :31.60                          Max.   :41.40                       
##  February_Average_Temperature_Pennsylvania March_Average_Temperature
##  Min.   :15.20                             Min.   :35.44            
##  1st Qu.:23.60                             1st Qu.:39.38            
##  Median :26.95                             Median :41.81            
##  Mean   :26.52                             Mean   :41.70            
##  3rd Qu.:29.80                             3rd Qu.:43.56            
##  Max.   :35.80                             Max.   :50.41            
##  March_Average_Temperature_Northeast March_Average_Temperature_Midwest
##  Min.   :24.20                       Min.   :28.50                    
##  1st Qu.:29.70                       1st Qu.:39.08                    
##  Median :32.55                       Median :42.85                    
##  Mean   :32.37                       Mean   :42.57                    
##  3rd Qu.:34.80                       3rd Qu.:45.60                    
##  Max.   :43.40                       Max.   :56.30                    
##  March_Average_Temperature_Pennsylvania
##  Min.   :24.50                         
##  1st Qu.:32.95                         
##  Median :35.85                         
##  Mean   :35.91                         
##  3rd Qu.:38.55                         
##  Max.   :47.70
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get variable names}
\KeywordTok{colnames}\NormalTok{(groundhog_predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Year"                                     
##  [2] "Punxsutawney_Phil"                        
##  [3] "February_Average_Temperature"             
##  [4] "February_Average_Temperature_Northeast"   
##  [5] "February_Average_Temperature_Midwest"     
##  [6] "February_Average_Temperature_Pennsylvania"
##  [7] "March_Average_Temperature"                
##  [8] "March_Average_Temperature_Northeast"      
##  [9] "March_Average_Temperature_Midwest"        
## [10] "March_Average_Temperature_Pennsylvania"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(groundhog_predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Year"                                     
##  [2] "Punxsutawney_Phil"                        
##  [3] "February_Average_Temperature"             
##  [4] "February_Average_Temperature_Northeast"   
##  [5] "February_Average_Temperature_Midwest"     
##  [6] "February_Average_Temperature_Pennsylvania"
##  [7] "March_Average_Temperature"                
##  [8] "March_Average_Temperature_Northeast"      
##  [9] "March_Average_Temperature_Midwest"        
## [10] "March_Average_Temperature_Pennsylvania"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# check the categorical variable}
\KeywordTok{unique}\NormalTok{(groundhog_predictions}\OperatorTok{$}\NormalTok{Punxsutawney_Phil)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "No Record"      "Full Shadow"    "No Shadow"      "Partial Shadow"
\end{verbatim}

\textbf{CHALLENGE}

Which variables are numeric? Which are categorical?

\hypertarget{the-pipe}{%
\section{The Pipe}\label{the-pipe}}

We will be using the package \texttt{dplyr} (which is also part of \texttt{tidyverse}) to do an exploratory analysis of our data.

The package \texttt{dplyr} most used function is \texttt{\%\textgreater{}\%} (called the pipe). The pipe allows you to ``pipe'' (or redirect) objects into functions. (hint: use ctrl+shift+m or cmd+shift+m as a shortcut for typing \texttt{\%\textgreater{}\%}).

Here's how to pipe the \texttt{avocado\_data} object into the \texttt{summary()} function

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get an overview of the data frame}
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Year      Punxsutawney_Phil  February_Average_Temperature
##  Min.   :1895   Length:122         Min.   :25.23               
##  1st Qu.:1925   Class :character   1st Qu.:31.78               
##  Median :1956   Mode  :character   Median :33.69               
##  Mean   :1956                      Mean   :33.80               
##  3rd Qu.:1986                      3rd Qu.:36.01               
##  Max.   :2016                      Max.   :41.41               
##  February_Average_Temperature_Northeast February_Average_Temperature_Midwest
##  Min.   :10.40                          Min.   :20.30                       
##  1st Qu.:20.02                          1st Qu.:29.62                       
##  Median :22.95                          Median :33.20                       
##  Mean   :22.69                          Mean   :32.69                       
##  3rd Qu.:25.98                          3rd Qu.:36.30                       
##  Max.   :31.60                          Max.   :41.40                       
##  February_Average_Temperature_Pennsylvania March_Average_Temperature
##  Min.   :15.20                             Min.   :35.44            
##  1st Qu.:23.60                             1st Qu.:39.38            
##  Median :26.95                             Median :41.81            
##  Mean   :26.52                             Mean   :41.70            
##  3rd Qu.:29.80                             3rd Qu.:43.56            
##  Max.   :35.80                             Max.   :50.41            
##  March_Average_Temperature_Northeast March_Average_Temperature_Midwest
##  Min.   :24.20                       Min.   :28.50                    
##  1st Qu.:29.70                       1st Qu.:39.08                    
##  Median :32.55                       Median :42.85                    
##  Mean   :32.37                       Mean   :42.57                    
##  3rd Qu.:34.80                       3rd Qu.:45.60                    
##  Max.   :43.40                       Max.   :56.30                    
##  March_Average_Temperature_Pennsylvania
##  Min.   :24.50                         
##  1st Qu.:32.95                         
##  Median :35.85                         
##  Mean   :35.91                         
##  3rd Qu.:38.55                         
##  Max.   :47.70
\end{verbatim}

The pipe allows us to apply multiple functions to the same object.

Let's start by selecting one column in our data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(Punxsutawney_Phil)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 122 x 1
##    Punxsutawney_Phil
##    <chr>            
##  1 No Record        
##  2 No Record        
##  3 No Record        
##  4 Full Shadow      
##  5 No Record        
##  6 Full Shadow      
##  7 Full Shadow      
##  8 No Record        
##  9 Full Shadow      
## 10 Full Shadow      
## # ... with 112 more rows
\end{verbatim}

Now let's add another pipe to get unique values in this column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(Punxsutawney_Phil) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{unique}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 1
##   Punxsutawney_Phil
##   <chr>            
## 1 No Record        
## 2 Full Shadow      
## 3 No Shadow        
## 4 Partial Shadow
\end{verbatim}

\hypertarget{counting-categorical-variables}{%
\section{Counting Categorical Variables}\label{counting-categorical-variables}}

One of the functions I most use when exploring my data is \texttt{count()}, which you can combine with \texttt{\%\textgreater{}\%}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{count}\NormalTok{(Punxsutawney_Phil)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   Punxsutawney_Phil     n
##   <chr>             <int>
## 1 Full Shadow         100
## 2 No Record             6
## 3 No Shadow            15
## 4 Partial Shadow        1
\end{verbatim}

You can do the same adding \texttt{group\_by()} to your pipeline.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Punxsutawney_Phil) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
## # Groups:   Punxsutawney_Phil [4]
##   Punxsutawney_Phil     n
##   <chr>             <int>
## 1 Full Shadow         100
## 2 No Record             6
## 3 No Shadow            15
## 4 Partial Shadow        1
\end{verbatim}

And instead of \texttt{count()} we can use the \texttt{summarise()} and \texttt{n()} functions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Punxsutawney_Phil) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{total =} \KeywordTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 4 x 2
##   Punxsutawney_Phil total
##   <chr>             <int>
## 1 Full Shadow         100
## 2 No Record             6
## 3 No Shadow            15
## 4 Partial Shadow        1
\end{verbatim}

\textbf{CHALLENGE}

This last way of counting categorical variables (with \texttt{summarise()} and \texttt{n()}) outputs a data frame that is slightly different from the previous too. What's the difference?

\hypertarget{group_by-summarise}{%
\section{group\_by + summarise}\label{group_by-summarise}}

The combination of the \texttt{group\_by()} and \texttt{summarise()} functions is very powerful. In addition to using the \texttt{n()} function to count how many rows per each category in our categorical variable, we can use other functions with numeric (i.e., quantitative) variable such as \texttt{sum()} and \texttt{mean()}.

\textbf{CHALLENGE}

Take a moment to revisit the question we want to answer.

\begin{itemize}
\item
  What do we want to find out?
\item
  How can we answer our question with this data?
\item
  What function (e.g., \texttt{sum()}, \texttt{max()}, \texttt{mean()}) do we use to answer our question? With what variables/columns?
\end{itemize}

Complete the code below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Punxsutawney_Phil) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{total =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{____ =} \KeywordTok{____}\NormalTok{(____))}
\end{Highlighting}
\end{Shaded}

Example of output that you might want to get to answer our question:

\begin{verbatim}
## # A tibble: 4 x 4
##   Punxsutawney_Phil total feb_mean_temp mar_mean_temp
##   <chr>             <int>         <dbl>         <dbl>
## 1 Full Shadow         100          33.7          41.7
## 2 No Record             6          31.4          39.1
## 3 No Shadow            15          35.6          43.0
## 4 Partial Shadow        1          30.7          41.3
\end{verbatim}

\hypertarget{group_by-filter}{%
\section{group\_by + filter}\label{group_by-filter}}

The output above contains six \texttt{No\ Record} observations and only one \texttt{Partial\ Shadow}. We can keep just observations that are \texttt{Full\ Shadow} and \texttt{No\ Shadow} by using the filter() function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(Punxsutawney_Phil }\OperatorTok{==}\StringTok{ "Full Shadow"} \OperatorTok{|}
\StringTok{           }\NormalTok{Punxsutawney_Phil }\OperatorTok{==}\StringTok{ "No Shadow"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(Punxsutawney_Phil)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   Punxsutawney_Phil     n
##   <chr>             <int>
## 1 Full Shadow         100
## 2 No Shadow            15
\end{verbatim}

\textbf{CHALLENGE}

Add a \texttt{filter()} to your solution from the previous challenge.

Example of output that you might want to get:

\begin{verbatim}
## # A tibble: 2 x 4
##   Punxsutawney_Phil total feb_mean_temp mar_mean_temp
##   <chr>             <int>         <dbl>         <dbl>
## 1 Full Shadow         100          33.7          41.7
## 2 No Shadow            15          35.6          43.0
\end{verbatim}

\hypertarget{pivot-dataframe}{%
\section{Pivot Dataframe}\label{pivot-dataframe}}

Another useful function we will be using a lot during this course is \texttt{pivot\_longer()}, which pivots (or tilts) some columns in our dataframe so we have one column for each of our variables.

Let's first select the temperatures for individual regions and create a new dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{selected_predictions <-}\StringTok{ }\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(Year, Punxsutawney_Phil, }
\NormalTok{         February_Average_Temperature_Northeast, }
\NormalTok{         February_Average_Temperature_Midwest,}
\NormalTok{         February_Average_Temperature_Pennsylvania,}
\NormalTok{         March_Average_Temperature_Northeast,}
\NormalTok{         March_Average_Temperature_Midwest,}
\NormalTok{         March_Average_Temperature_Pennsylvania)}

\KeywordTok{colnames}\NormalTok{(selected_predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Year"                                     
## [2] "Punxsutawney_Phil"                        
## [3] "February_Average_Temperature_Northeast"   
## [4] "February_Average_Temperature_Midwest"     
## [5] "February_Average_Temperature_Pennsylvania"
## [6] "March_Average_Temperature_Northeast"      
## [7] "March_Average_Temperature_Midwest"        
## [8] "March_Average_Temperature_Pennsylvania"
\end{verbatim}

Another way of doing the same thing we just did is by saying the columns we want to eliminate from our selection, using the \texttt{-} (i.e, minus) sign.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{selected_predictions <-}\StringTok{ }\NormalTok{groundhog_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{February_Average_Temperature, }\OperatorTok{-}\NormalTok{March_Average_Temperature)}

\KeywordTok{colnames}\NormalTok{(selected_predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Year"                                     
## [2] "Punxsutawney_Phil"                        
## [3] "February_Average_Temperature_Northeast"   
## [4] "February_Average_Temperature_Midwest"     
## [5] "February_Average_Temperature_Pennsylvania"
## [6] "March_Average_Temperature_Northeast"      
## [7] "March_Average_Temperature_Midwest"        
## [8] "March_Average_Temperature_Pennsylvania"
\end{verbatim}

Now we are ready to \texttt{pivot\_longer()} our selected\_predictions dataframe. Let's examine our selected\_predictions dataframe. We want to move all numbers to our numeric variable called temperature, and we want the column names to be another variable called \texttt{month\_region} so that are data is tidy.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(selected_predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 8
##    Year Punxsutawney_Ph~ February_Averag~ February_Averag~ February_Averag~
##   <dbl> <chr>                       <dbl>            <dbl>            <dbl>
## 1  1895 No Record                    15.6             21.9             17  
## 2  1896 No Record                    22.2             33.5             26.6
## 3  1897 No Record                    23.6             34.7             27.9
## 4  1898 Full Shadow                  24.8             33.3             26.7
## 5  1899 No Record                    18.1             22.2             20  
## 6  1900 Full Shadow                  21.4             27.5             24.1
## # ... with 3 more variables: March_Average_Temperature_Northeast <dbl>,
## #   March_Average_Temperature_Midwest <dbl>,
## #   March_Average_Temperature_Pennsylvania <dbl>
\end{verbatim}

Again we can list all the columns we want to pivot (i.e., all the columns that are numeric), but we have a smaller number of columns we don't want to pivot, so we use the \texttt{-} (minus) symbol with the columns we don't want to pivot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{selected_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\DataTypeTok{cols =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\NormalTok{Year, }\OperatorTok{-}\NormalTok{Punxsutawney_Phil))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 732 x 4
##     Year Punxsutawney_Phil name                                      value
##    <dbl> <chr>             <chr>                                     <dbl>
##  1  1895 No Record         February_Average_Temperature_Northeast     15.6
##  2  1895 No Record         February_Average_Temperature_Midwest       21.9
##  3  1895 No Record         February_Average_Temperature_Pennsylvania  17  
##  4  1895 No Record         March_Average_Temperature_Northeast        27.6
##  5  1895 No Record         March_Average_Temperature_Midwest          40.2
##  6  1895 No Record         March_Average_Temperature_Pennsylvania     31.3
##  7  1896 No Record         February_Average_Temperature_Northeast     22.2
##  8  1896 No Record         February_Average_Temperature_Midwest       33.5
##  9  1896 No Record         February_Average_Temperature_Pennsylvania  26.6
## 10  1896 No Record         March_Average_Temperature_Northeast        25.3
## # ... with 722 more rows
\end{verbatim}

We can specify the column names so they are not just \texttt{name} and \texttt{value}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{selected_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\DataTypeTok{cols =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\NormalTok{Year, }\OperatorTok{-}\NormalTok{Punxsutawney_Phil),}
               \DataTypeTok{names_to =} \StringTok{"month_region"}\NormalTok{,}
               \DataTypeTok{values_to =} \StringTok{"temperature"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 732 x 4
##     Year Punxsutawney_Phil month_region                              temperature
##    <dbl> <chr>             <chr>                                           <dbl>
##  1  1895 No Record         February_Average_Temperature_Northeast           15.6
##  2  1895 No Record         February_Average_Temperature_Midwest             21.9
##  3  1895 No Record         February_Average_Temperature_Pennsylvania        17  
##  4  1895 No Record         March_Average_Temperature_Northeast              27.6
##  5  1895 No Record         March_Average_Temperature_Midwest                40.2
##  6  1895 No Record         March_Average_Temperature_Pennsylvania           31.3
##  7  1896 No Record         February_Average_Temperature_Northeast           22.2
##  8  1896 No Record         February_Average_Temperature_Midwest             33.5
##  9  1896 No Record         February_Average_Temperature_Pennsylvania        26.6
## 10  1896 No Record         March_Average_Temperature_Northeast              25.3
## # ... with 722 more rows
\end{verbatim}

Let's save the result above in a new dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predictions_tidy <-}\StringTok{ }\NormalTok{selected_predictions }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\DataTypeTok{cols =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\NormalTok{Year, }\OperatorTok{-}\NormalTok{Punxsutawney_Phil),}
               \DataTypeTok{names_to =} \StringTok{"month_region"}\NormalTok{,}
               \DataTypeTok{values_to =} \StringTok{"temperature"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{separating-one-categorical-column-into-two}{%
\section{Separating one categorical column into two}\label{separating-one-categorical-column-into-two}}

When we look at our \texttt{predictions\_tidy}, we see that the \texttt{month\_region} is actually holding two categorical variables. We can separate this column into its two variables with the \texttt{separate()} function. There are four parts to each of the values, the two middle parts are not useful so we name the first part \texttt{month} the last \texttt{region} and the other two not useful parts (the middle two) \texttt{trash1} and \texttt{trash2}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predictions_tidy_v2 <-}\StringTok{ }\NormalTok{predictions_tidy }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{separate}\NormalTok{(}\DataTypeTok{col =}\NormalTok{ month_region,}
           \DataTypeTok{into =} \KeywordTok{c}\NormalTok{(}\StringTok{"month"}\NormalTok{, }\StringTok{"trash1"}\NormalTok{, }\StringTok{"trash2"}\NormalTok{, }\StringTok{"region"}\NormalTok{)) }

\NormalTok{predictions_tidy_v2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 732 x 7
##     Year Punxsutawney_Phil month    trash1  trash2      region       temperature
##    <dbl> <chr>             <chr>    <chr>   <chr>       <chr>              <dbl>
##  1  1895 No Record         February Average Temperature Northeast           15.6
##  2  1895 No Record         February Average Temperature Midwest             21.9
##  3  1895 No Record         February Average Temperature Pennsylvania        17  
##  4  1895 No Record         March    Average Temperature Northeast           27.6
##  5  1895 No Record         March    Average Temperature Midwest             40.2
##  6  1895 No Record         March    Average Temperature Pennsylvania        31.3
##  7  1896 No Record         February Average Temperature Northeast           22.2
##  8  1896 No Record         February Average Temperature Midwest             33.5
##  9  1896 No Record         February Average Temperature Pennsylvania        26.6
## 10  1896 No Record         March    Average Temperature Northeast           25.3
## # ... with 722 more rows
\end{verbatim}

We can delete the two not useful columns (i.e., \texttt{trash1} and \texttt{trash2}) by using the \texttt{select()} and \texttt{-} (minus) symbol.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predictions_tidy_v2 <-}\StringTok{ }\NormalTok{predictions_tidy_v2 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{trash1, }\OperatorTok{-}\NormalTok{trash2)}
\end{Highlighting}
\end{Shaded}

\hypertarget{example-of-plotting}{%
\section{Example of Plotting}\label{example-of-plotting}}

Now that we have our tidy dataframe (i.e., \texttt{predictions\_tidy\_v2}), we can plot temperatures by year:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predictions_tidy_v2 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }
             \DataTypeTok{y =}\NormalTok{ temperature)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ month))}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-48-1.pdf}

\hypertarget{data-challenge-01}{%
\section{DATA CHALLENGE 01}\label{data-challenge-01}}

Accept \href{https://classroom.github.com/a/0CjzlvtW}{data challenge 01 assignment}

\hypertarget{data-wrangling}{%
\chapter{Data Wrangling}\label{data-wrangling}}

\hypertarget{load-libraries}{%
\section{Load libraries}\label{load-libraries}}

Load tidyverse using \texttt{library()}

Our data for this module is an excel spreadsheet, so we need to install a new package to handle this type of data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"readxl"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{read-your-data-in}{%
\section{Read your data in}\label{read-your-data-in}}

After \texttt{readxl} package installation is done:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  load \texttt{readxl} using \texttt{library()}
\item
  check your working environment with \texttt{getwd()} and \texttt{dir()}
\item
  load your data
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary <-}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}\StringTok{"data/nfl_salary.xlsx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  inspect your data with \texttt{summary()}, \texttt{glimpse()} and \texttt{View()}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(nfl_salary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 800
## Columns: 11
## $ year                <dbl> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,...
## $ Cornerback          <dbl> 11265916, 11000000, 10000000, 10000000, 1000000...
## $ `Defensive Lineman` <dbl> 17818000, 16200000, 12476000, 11904706, 1176278...
## $ Linebacker          <dbl> 16420000, 15623000, 11825000, 10083333, 1002000...
## $ `Offensive Lineman` <dbl> 15960000, 12800000, 11767500, 10358200, 1000000...
## $ Quarterback         <dbl> 17228125, 16000000, 14400000, 14100000, 1351000...
## $ `Running Back`      <dbl> 12955000, 10873833, 9479000, 7700000, 7500000, ...
## $ Safety              <dbl> 8871428, 8787500, 8282500, 8000000, 7804333, 76...
## $ `Special Teamer`    <dbl> 4300000, 3725000, 3556176, 3500000, 3250000, 32...
## $ `Tight End`         <dbl> 8734375, 8591000, 8290000, 7723333, 6974666, 61...
## $ `Wide Receiver`     <dbl> 16250000, 14175000, 11424000, 11415000, 1080000...
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  How many observations are there?
\item
  What variables are there in the data?
\end{enumerate}

\hypertarget{summarise-data}{%
\section{Summarise data}\label{summarise-data}}

QUESTIONS:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Have salaries for different NFL positions increased between 2011 and 2018?
\item
  What positions pay more and less?
\end{enumerate}

Let's summarise the \texttt{mean} salary for Quarterback \texttt{by\ year}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{quarterback_mean_salary =} \KeywordTok{mean}\NormalTok{(Quarterback, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 8 x 2
##    year quarterback_mean_salary
##   <dbl>                   <dbl>
## 1  2011                3376113.
## 2  2012                3496408.
## 3  2013                3450185.
## 4  2014                4234160.
## 5  2015                4225789.
## 6  2016                5499939.
## 7  2017                5329727.
## 8  2018                6593769.
\end{verbatim}

What would we do to add the mean salary for \texttt{Cornerback}?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{quarterback_mean_salary =} \KeywordTok{mean}\NormalTok{(Quarterback, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
            \DataTypeTok{cornerback_mean_salary =} \KeywordTok{mean}\NormalTok{(Cornerback, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 8 x 3
##    year quarterback_mean_salary cornerback_mean_salary
##   <dbl>                   <dbl>                  <dbl>
## 1  2011                3376113.               3037766.
## 2  2012                3496408.               3132916.
## 3  2013                3450185.               2901798.
## 4  2014                4234160.               3038278.
## 5  2015                4225789.               3758543.
## 6  2016                5499939.               4201470.
## 7  2017                5329727.               4125692.
## 8  2018                6593769.               4659704.
\end{verbatim}

Let's stop and think about how our data is organized. Is our data tidy?

We have columns that mix two type of variables:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  categorical variable for position
\item
  numeric variable for salary
\end{enumerate}

\hypertarget{tidy-data}{%
\section{Tidy data}\label{tidy-data}}

In order to make our data easier to work with, we need to make sure each column in our data represents just one variable. To do that for our \texttt{nfl\_salary} dataframe, we need to pivot it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy <-}\StringTok{ }\NormalTok{nfl_salary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\DataTypeTok{cols =} \OperatorTok{-}\NormalTok{year,}
               \DataTypeTok{names_to =} \StringTok{"position"}\NormalTok{,}
               \DataTypeTok{values_to =} \StringTok{"salary"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Always inspect your new data frame.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(nfl_salary_tidy)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 8,000
## Columns: 3
## $ year     <dbl> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011...
## $ position <chr> "Cornerback", "Defensive Lineman", "Linebacker", "Offensiv...
## $ salary   <dbl> 11265916, 17818000, 16420000, 15960000, 17228125, 12955000...
\end{verbatim}

How many positions are there in the data? We can now do a \texttt{count()} with our categorical variable for \texttt{position}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(position)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    position              n
##    <chr>             <int>
##  1 Cornerback          800
##  2 Defensive Lineman   800
##  3 Linebacker          800
##  4 Offensive Lineman   800
##  5 Quarterback         800
##  6 Running Back        800
##  7 Safety              800
##  8 Special Teamer      800
##  9 Tight End           800
## 10 Wide Receiver       800
\end{verbatim}

We can add \texttt{year} to our \texttt{group\_by} to check how many observations per \texttt{position} across \texttt{year}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(position, year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 80 x 3
##    position           year     n
##    <chr>             <dbl> <int>
##  1 Cornerback         2011   100
##  2 Cornerback         2012   100
##  3 Cornerback         2013   100
##  4 Cornerback         2014   100
##  5 Cornerback         2015   100
##  6 Cornerback         2016   100
##  7 Cornerback         2017   100
##  8 Cornerback         2018   100
##  9 Defensive Lineman  2011   100
## 10 Defensive Lineman  2012   100
## # ... with 70 more rows
\end{verbatim}

Let's check for NAs (i.e., missing data), we can do that by using \texttt{is.na()} and \texttt{filter()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(position, year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 3
##   position        year     n
##   <chr>          <dbl> <int>
## 1 Quarterback     2011     3
## 2 Quarterback     2012    12
## 3 Quarterback     2013     7
## 4 Quarterback     2014    11
## 5 Quarterback     2015     3
## 6 Quarterback     2016     5
## 7 Quarterback     2017     3
## 8 Quarterback     2018    11
## 9 Special Teamer  2011     1
\end{verbatim}

We can remove these rows from our data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean <-}\StringTok{ }\NormalTok{nfl_salary_tidy }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(salary))}
\end{Highlighting}
\end{Shaded}

Inspect your new data frame.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(nfl_salary_tidy_clean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 7,944
## Columns: 3
## $ year     <dbl> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011...
## $ position <chr> "Cornerback", "Defensive Lineman", "Linebacker", "Offensiv...
## $ salary   <dbl> 11265916, 17818000, 16420000, 15960000, 17228125, 12955000...
\end{verbatim}

Now we can do our salary \texttt{summarise()} in a cleaner way. We are going to do a \texttt{mean()} of our numeric variable \texttt{salary} by \texttt{year} AND \texttt{position}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_salary =} \KeywordTok{mean}\NormalTok{(salary))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 3
## # Groups:   year [8]
##     year position          mean_salary
##    <dbl> <chr>                   <dbl>
##  1  2011 Cornerback           3037766.
##  2  2011 Defensive Lineman    4306995.
##  3  2011 Linebacker           4016045.
##  4  2011 Offensive Lineman    4662748.
##  5  2011 Quarterback          3376113.
##  6  2011 Running Back         1976341.
##  7  2011 Safety               2241891.
##  8  2011 Special Teamer       1244069.
##  9  2011 Tight End            1608100.
## 10  2011 Wide Receiver        2996590.
## # ... with 70 more rows
\end{verbatim}

We can do the group\_by both ways (first \texttt{year} and then \texttt{position} or vice-versa).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(position, year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_salary =} \KeywordTok{mean}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(mean_salary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'position' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 3
## # Groups:   position [10]
##    position        year mean_salary
##    <chr>          <dbl>       <dbl>
##  1 Special Teamer  2013    1235892.
##  2 Special Teamer  2011    1244069.
##  3 Special Teamer  2014    1264493.
##  4 Special Teamer  2012    1313043.
##  5 Special Teamer  2015    1348637.
##  6 Special Teamer  2016    1394443.
##  7 Special Teamer  2017    1459552.
##  8 Special Teamer  2018    1571447.
##  9 Tight End       2011    1608100.
## 10 Tight End       2012    1664520.
## # ... with 70 more rows
\end{verbatim}

Add a \texttt{-} (minus) sign to the argument in \texttt{arrange()} to arrange your results by decreasing order of mean\_salary.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(position, year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_salary =} \KeywordTok{mean}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\OperatorTok{-}\NormalTok{mean_salary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'position' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 3
## # Groups:   position [10]
##    position           year mean_salary
##    <chr>             <dbl>       <dbl>
##  1 Offensive Lineman  2018    7522647.
##  2 Defensive Lineman  2018    7202360.
##  3 Quarterback        2018    6593769.
##  4 Offensive Lineman  2017    6370947.
##  5 Defensive Lineman  2017    6202601.
##  6 Wide Receiver      2018    5627721.
##  7 Quarterback        2016    5499939.
##  8 Offensive Lineman  2016    5410392.
##  9 Quarterback        2017    5329727.
## 10 Linebacker         2018    5293675.
## # ... with 70 more rows
\end{verbatim}

We can also add \texttt{arrange()} to our code block.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(position, year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_salary =} \KeywordTok{mean}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'position' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 3
## # Groups:   position [10]
##    position           year mean_salary
##    <chr>             <dbl>       <dbl>
##  1 Cornerback         2011    3037766.
##  2 Cornerback         2012    3132916.
##  3 Cornerback         2013    2901798.
##  4 Cornerback         2014    3038278.
##  5 Cornerback         2015    3758543.
##  6 Cornerback         2016    4201470.
##  7 Cornerback         2017    4125692.
##  8 Cornerback         2018    4659704.
##  9 Defensive Lineman  2011    4306995.
## 10 Defensive Lineman  2012    4693730.
## # ... with 70 more rows
\end{verbatim}

\hypertarget{viz-demo}{%
\subsection{Viz Demo}\label{viz-demo}}

We can also visualize our data using \texttt{ggplot()}.

First we save our summary results in a new dataframe called \texttt{nfl\_salary\_summary}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_summary <-}\StringTok{ }\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(position, year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_salary =} \KeywordTok{mean}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'position' (override with `.groups` argument)
\end{verbatim}

Then we plot it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_summary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ mean_salary,}
             \DataTypeTok{color =}\NormalTok{ position,}
             \DataTypeTok{group =}\NormalTok{ position)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-67-1.pdf}

\hypertarget{transform-data}{%
\section{Transform Data}\label{transform-data}}

Now that our data is tidy, we can transform our data by adding new variables/columns to it.

It seems some salaries for certain positions show a higher increase across the years than the salaries for other positions. In other words, the proportion of what position makes in relation to total money spent in salaries for each each.

We can check this is true by creating a \texttt{sum()} of salaries for each year and a count of players using \texttt{n()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{player_count =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{total_per_position =} \KeywordTok{sum}\NormalTok{(salary)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 4
## # Groups:   year [8]
##     year position          player_count total_per_position
##    <dbl> <chr>                    <int>              <dbl>
##  1  2011 Cornerback                 100          303776605
##  2  2011 Defensive Lineman          100          430699528
##  3  2011 Linebacker                 100          401604548
##  4  2011 Offensive Lineman          100          466274753
##  5  2011 Quarterback                 97          327482939
##  6  2011 Running Back               100          197634074
##  7  2011 Safety                     100          224189136
##  8  2011 Special Teamer              99          123162874
##  9  2011 Tight End                  100          160810030
## 10  2011 Wide Receiver              100          299659044
## # ... with 70 more rows
\end{verbatim}

We can then add \texttt{mutate()} to our code block to calculate \texttt{sum()} of all salaries per year.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{player_count =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{total_per_position =} \KeywordTok{sum}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{total_per_year =} \KeywordTok{sum}\NormalTok{(total_per_position)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 5
## # Groups:   year [8]
##     year position          player_count total_per_position total_per_year
##    <dbl> <chr>                    <int>              <dbl>          <dbl>
##  1  2011 Cornerback                 100          303776605     2935293531
##  2  2011 Defensive Lineman          100          430699528     2935293531
##  3  2011 Linebacker                 100          401604548     2935293531
##  4  2011 Offensive Lineman          100          466274753     2935293531
##  5  2011 Quarterback                 97          327482939     2935293531
##  6  2011 Running Back               100          197634074     2935293531
##  7  2011 Safety                     100          224189136     2935293531
##  8  2011 Special Teamer              99          123162874     2935293531
##  9  2011 Tight End                  100          160810030     2935293531
## 10  2011 Wide Receiver              100          299659044     2935293531
## # ... with 70 more rows
\end{verbatim}

Now we can calculate the percentage cost of each position by the total salaries for each year, we can do that all in the same \texttt{mutate()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{player_count =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{total_per_position =} \KeywordTok{sum}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{total_per_year =} \KeywordTok{sum}\NormalTok{(total_per_position),}
         \DataTypeTok{percentage_cost =}\NormalTok{ total_per_position}\OperatorTok{/}\NormalTok{total_per_year) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 6
## # Groups:   year [8]
##     year position   player_count total_per_posit~ total_per_year percentage_cost
##    <dbl> <chr>             <int>            <dbl>          <dbl>           <dbl>
##  1  2011 Cornerback          100        303776605     2935293531          0.103 
##  2  2011 Defensive~          100        430699528     2935293531          0.147 
##  3  2011 Linebacker          100        401604548     2935293531          0.137 
##  4  2011 Offensive~          100        466274753     2935293531          0.159 
##  5  2011 Quarterba~           97        327482939     2935293531          0.112 
##  6  2011 Running B~          100        197634074     2935293531          0.0673
##  7  2011 Safety              100        224189136     2935293531          0.0764
##  8  2011 Special T~           99        123162874     2935293531          0.0420
##  9  2011 Tight End           100        160810030     2935293531          0.0548
## 10  2011 Wide Rece~          100        299659044     2935293531          0.102 
## # ... with 70 more rows
\end{verbatim}

Add \texttt{arrange()} to see higher percentages at the top.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{player_count =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{total_per_position =} \KeywordTok{sum}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{total_per_year =} \KeywordTok{sum}\NormalTok{(total_per_position),}
         \DataTypeTok{percentage_cost =}\NormalTok{ total_per_position}\OperatorTok{/}\NormalTok{total_per_year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\OperatorTok{-}\NormalTok{percentage_cost)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 80 x 6
## # Groups:   year [8]
##     year position   player_count total_per_posit~ total_per_year percentage_cost
##    <dbl> <chr>             <int>            <dbl>          <dbl>           <dbl>
##  1  2018 Offensive~          100        752264724     4557047519           0.165
##  2  2014 Defensive~          100        503535499     3154183189           0.160
##  3  2011 Offensive~          100        466274753     2935293531           0.159
##  4  2017 Offensive~          100        637094749     4027571325           0.158
##  5  2018 Defensive~          100        720236012     4557047519           0.158
##  6  2013 Defensive~          100        454787761     2920039442           0.156
##  7  2014 Offensive~          100        489885308     3154183189           0.155
##  8  2013 Offensive~          100        453489965     2920039442           0.155
##  9  2012 Defensive~          100        469373045     3032589536           0.155
## 10  2017 Defensive~          100        620260110     4027571325           0.154
## # ... with 70 more rows
\end{verbatim}

\hypertarget{viz-demo-1}{%
\subsection{Viz Demo}\label{viz-demo-1}}

We can also visualize our data using \texttt{ggplot()}.

First we save our summary results in a new dataframe called \texttt{nfl\_salary\_summary}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_summary <-}\StringTok{ }\NormalTok{nfl_salary_tidy_clean }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{player_count =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{total_per_position =} \KeywordTok{sum}\NormalTok{(salary)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{total_per_year =} \KeywordTok{sum}\NormalTok{(total_per_position),}
         \DataTypeTok{percentage_cost =}\NormalTok{ total_per_position}\OperatorTok{/}\NormalTok{total_per_year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\OperatorTok{-}\NormalTok{percentage_cost)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

Then we plot it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfl_salary_summary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ percentage_cost,}
             \DataTypeTok{color =}\NormalTok{ position,}
             \DataTypeTok{group =}\NormalTok{ position)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-73-1.pdf}

\hypertarget{data-challenge-02}{%
\section{DATA CHALLENGE 02}\label{data-challenge-02}}

Accept \href{https://classroom.github.com/a/DhH5ciNQ}{data challenge 02 assignment}

\hypertarget{data-visualization}{%
\chapter{Data Visualization}\label{data-visualization}}

\hypertarget{the-layered-grammar-of-graphics}{%
\section{The layered grammar of graphics}\label{the-layered-grammar-of-graphics}}

The package we will be using for plotting in this class is called \texttt{ggplot2} which is part of \texttt{tidyverse}, and it uses as a principle the idea of layered grammar of graphics. That means you can add code to add or change your plot in layers, by using the \texttt{+} symbol.

Let's start with some data, so we can created different plots using different layers.

\hypertarget{load-data}{%
\section{Load data}\label{load-data}}

Get data directly from \href{https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv}{tidy tuesday github}.

\begin{verbatim}
## Rows: 32,833
## Columns: 23
## $ track_id                 <chr> "6f807x0ima9a1j3VPbc7VN", "0r7CVbZTWZgbTCY...
## $ track_name               <chr> "I Don't Care (with Justin Bieber) - Loud ...
## $ track_artist             <chr> "Ed Sheeran", "Maroon 5", "Zara Larsson", ...
## $ track_popularity         <dbl> 66, 67, 70, 60, 69, 67, 62, 69, 68, 67, 58...
## $ track_album_id           <chr> "2oCs0DGTsRO98Gh5ZSl2Cx", "63rPSO264uRjW1X...
## $ track_album_name         <chr> "I Don't Care (with Justin Bieber) [Loud L...
## $ track_album_release_date <chr> "2019-06-14", "2019-12-13", "2019-07-05", ...
## $ playlist_name            <chr> "Pop Remix", "Pop Remix", "Pop Remix", "Po...
## $ playlist_id              <chr> "37i9dQZF1DXcZDD7cfEKhW", "37i9dQZF1DXcZDD...
## $ playlist_genre           <chr> "pop", "pop", "pop", "pop", "pop", "pop", ...
## $ playlist_subgenre        <chr> "dance pop", "dance pop", "dance pop", "da...
## $ danceability             <dbl> 0.748, 0.726, 0.675, 0.718, 0.650, 0.675, ...
## $ energy                   <dbl> 0.916, 0.815, 0.931, 0.930, 0.833, 0.919, ...
## $ key                      <dbl> 6, 11, 1, 7, 1, 8, 5, 4, 8, 2, 6, 8, 1, 5,...
## $ loudness                 <dbl> -2.634, -4.969, -3.432, -3.778, -4.672, -5...
## $ mode                     <dbl> 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, ...
## $ speechiness              <dbl> 0.0583, 0.0373, 0.0742, 0.1020, 0.0359, 0....
## $ acousticness             <dbl> 0.10200, 0.07240, 0.07940, 0.02870, 0.0803...
## $ instrumentalness         <dbl> 0.00e+00, 4.21e-03, 2.33e-05, 9.43e-06, 0....
## $ liveness                 <dbl> 0.0653, 0.3570, 0.1100, 0.2040, 0.0833, 0....
## $ valence                  <dbl> 0.518, 0.693, 0.613, 0.277, 0.725, 0.585, ...
## $ tempo                    <dbl> 122.036, 99.972, 124.008, 121.956, 123.976...
## $ duration_ms              <dbl> 194754, 162600, 176616, 169093, 189052, 16...
\end{verbatim}

EXERCISE

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  What variables do we have in this data?
\item
  What questions can you ask about this data?
\end{enumerate}

\hypertarget{what-to-plot}{%
\section{What to plot?}\label{what-to-plot}}

The first thing you need to do is define what you want to plot. If you've never plotted data before, you might not be familiar with the different types of charts you can create.

Here's a few (can you tell what type of plot these are?):

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-75-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  What is the plot above called?
\item
  What variable(s) are we plotting?
\item
  What can we conclude based on this plot?
\end{enumerate}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-76-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  What is the plot above called?
\item
  What variable(s) are we plotting?
\item
  What can we conclude based on this plot?
\end{enumerate}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-77-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  What is the plot above called?
\item
  What variable(s) are we plotting?
\item
  What can we conclude based on this plot?
\end{enumerate}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-78-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  What is the plot above called?
\item
  What variable(s) are we plotting?
\item
  What can we conclude based on this plot?
\end{enumerate}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-79-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  What is the plot above called?
\item
  What variable(s) are we plotting?
\item
  What can we conclude based on this plot?
\end{enumerate}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-80-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  What is the plot above called?
\item
  What variable(s) are we plotting?
\item
  What can we conclude based on this plot?
\end{enumerate}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-81-1.pdf}

\hypertarget{aesthetic-mappings}{%
\section{Aesthetic Mappings}\label{aesthetic-mappings}}

You map your aesthetics using the \texttt{aes()} function, which can be place inside of the \texttt{ggplot()} function.

\hypertarget{one-continuous-variable}{%
\subsection{One continuous variable}\label{one-continuous-variable}}

You need to map at least one variable when you are plotting. Check the help for \texttt{geom\_histogram} to see what kind of variable you can plot in a histogram.

The variable \texttt{track\_popularity} is continuous.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_songs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ track_popularity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-82-1.pdf}

The variable \texttt{release\_year} is also continuous.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_songs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-83-1.pdf}

\hypertarget{two-numeric-variables}{%
\subsection{Two numeric variables}\label{two-numeric-variables}}

Two-dimensional plots have two axis, \texttt{x} (horizontal) and \texttt{y} (vertical).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_songs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year, }
             \DataTypeTok{y =}\NormalTok{ track_popularity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-84-1.pdf}

\hypertarget{geom_-i.e.-geometric-objects}{%
\section{geom\_ (i.e., Geometric Objects)}\label{geom_-i.e.-geometric-objects}}

Functions such as \texttt{geom\_histogram()}, \texttt{geom\_point()}, and \texttt{geom\_col()} are geometric objects and determine what type of plot R draws.

You can also map other elements of your chart in addition to position (i.e., \texttt{x} and \texttt{y}), such as color, size, and shape.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_songs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year, }
             \DataTypeTok{y =}\NormalTok{ track_popularity,}
             \DataTypeTok{color =}\NormalTok{ playlist_genre)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-85-1.pdf}

EXERCISE

Check the help page for \texttt{geom\_point} (enter \texttt{?geom\_point} in your console).
Change \texttt{geom\_point()} to the suggested variations in its help page.

\hypertarget{more-mappings-with-aes}{%
\section{More mappings with aes()}\label{more-mappings-with-aes}}

In addition to \texttt{color} you can also add \texttt{size} and \texttt{shape} to \texttt{aes()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_songs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year, }
             \DataTypeTok{y =}\NormalTok{ track_popularity,}
             \DataTypeTok{color =}\NormalTok{ playlist_subgenre,}
             \DataTypeTok{shape =}\NormalTok{ playlist_genre)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-86-1.pdf}

The plot above is too messy, there's too much information. You often need to transform your data before plotting it.

EXERCISE

Summarize mean \texttt{track\_popularity} by \texttt{release\_year}, \texttt{playlist\_genre} and \texttt{playlist\_subgenre}.

Your summarized data frame should look something like this:

\begin{verbatim}
## `summarise()` regrouping output by 'release_year', 'playlist_genre' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 883 x 4
## # Groups:   release_year, playlist_genre [302]
##    release_year playlist_genre playlist_subgenre  mean_popularity
##           <dbl> <chr>          <chr>                        <dbl>
##  1         1957 r&b            urban contemporary              59
##  2         1957 rock           classic rock                     1
##  3         1958 rock           classic rock                    73
##  4         1960 r&b            neo soul                        13
##  5         1960 r&b            urban contemporary              19
##  6         1961 r&b            urban contemporary              47
##  7         1962 r&b            urban contemporary              64
##  8         1962 rock           classic rock                    64
##  9         1963 r&b            neo soul                        73
## 10         1963 rock           album rock                      59
## # ... with 873 more rows
\end{verbatim}

Now you can plot your summarized data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_summary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year, }
             \DataTypeTok{y =}\NormalTok{ mean_popularity,}
             \DataTypeTok{color =}\NormalTok{ playlist_subgenre,}
             \DataTypeTok{shape =}\NormalTok{ playlist_genre)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-88-1.pdf}

Still super messy. Shape is not really a good way to do this.

Let's try a bar plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_summary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year, }
             \DataTypeTok{y =}\NormalTok{ mean_popularity,}
             \DataTypeTok{fill =}\NormalTok{ playlist_genre)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{(}\DataTypeTok{position =} \StringTok{"dodge"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-89-1.pdf}

Not great either, too much going on.

\hypertarget{facets}{%
\section{Facets}\label{facets}}

You can use the \texttt{facet\_wrap()} function to split your plotting into several smaller plots, usually by a categorical variable.

Let's try the scatterplot first.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_summary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year, }
             \DataTypeTok{y =}\NormalTok{ mean_popularity,}
             \DataTypeTok{color =}\NormalTok{ playlist_genre)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{playlist_subgenre)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-90-1.pdf}

What about a bar plot?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_summary }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ release_year, }
             \DataTypeTok{y =}\NormalTok{ mean_popularity,}
             \DataTypeTok{fill =}\NormalTok{ playlist_genre)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{(}\DataTypeTok{position =} \StringTok{"dodge"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{playlist_subgenre)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-91-1.pdf}

\hypertarget{more-summarize}{%
\section{More Summarize}\label{more-summarize}}

We can also plot categorical variables on the \texttt{x} axis.

EXERCISE

Summarize mean \texttt{track\_popularity} by \texttt{playlist\_genre}.

Your summarized data frame should look something like this:

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 2
##   playlist_genre mean_popularity
##   <chr>                    <dbl>
## 1 edm                       34.8
## 2 latin                     47.0
## 3 pop                       47.7
## 4 r&b                       41.2
## 5 rap                       43.2
## 6 rock                      41.7
\end{verbatim}

Now plot a bar chart mapping \texttt{x} to \texttt{playlist\_genre}, \texttt{y} to \texttt{mean\_popularity}.

Your plot should look something like this:

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-93-1.pdf}

\hypertarget{data-challenge-03}{%
\section{DATA CHALLENGE 03}\label{data-challenge-03}}

Accept \href{https://classroom.github.com/a/ndGrSqaq}{data challenge 03 assignment}

\hypertarget{data-visualization-ii}{%
\chapter{Data Visualization II}\label{data-visualization-ii}}

We will continue working with the spotify data set we worked with last week. The objectives of this module are as follows: by the end of this module you will be able to \ldots{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Explore a large data frame to decide what part of the data you want to focus on
\item
  Create subsets of your original data frame
\item
  Create summarizations of your data based on different variables
\item
  Plot these summarizations
\end{enumerate}

\begin{verbatim}
## Rows: 32,833
## Columns: 25
## $ track_id                 <chr> "6f807x0ima9a1j3VPbc7VN", "0r7CVbZTWZgbTCY...
## $ track_name               <chr> "I Don't Care (with Justin Bieber) - Loud ...
## $ track_artist             <chr> "Ed Sheeran", "Maroon 5", "Zara Larsson", ...
## $ track_popularity         <dbl> 66, 67, 70, 60, 69, 67, 62, 69, 68, 67, 58...
## $ track_album_id           <chr> "2oCs0DGTsRO98Gh5ZSl2Cx", "63rPSO264uRjW1X...
## $ track_album_name         <chr> "I Don't Care (with Justin Bieber) [Loud L...
## $ track_album_release_date <chr> "2019-06-14", "2019-12-13", "2019-07-05", ...
## $ playlist_name            <chr> "Pop Remix", "Pop Remix", "Pop Remix", "Po...
## $ playlist_id              <chr> "37i9dQZF1DXcZDD7cfEKhW", "37i9dQZF1DXcZDD...
## $ playlist_genre           <chr> "pop", "pop", "pop", "pop", "pop", "pop", ...
## $ playlist_subgenre        <chr> "dance pop", "dance pop", "dance pop", "da...
## $ danceability             <dbl> 0.748, 0.726, 0.675, 0.718, 0.650, 0.675, ...
## $ energy                   <dbl> 0.916, 0.815, 0.931, 0.930, 0.833, 0.919, ...
## $ key                      <dbl> 6, 11, 1, 7, 1, 8, 5, 4, 8, 2, 6, 8, 1, 5,...
## $ loudness                 <dbl> -2.634, -4.969, -3.432, -3.778, -4.672, -5...
## $ mode                     <dbl> 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, ...
## $ speechiness              <dbl> 0.0583, 0.0373, 0.0742, 0.1020, 0.0359, 0....
## $ acousticness             <dbl> 0.10200, 0.07240, 0.07940, 0.02870, 0.0803...
## $ instrumentalness         <dbl> 0.00e+00, 4.21e-03, 2.33e-05, 9.43e-06, 0....
## $ liveness                 <dbl> 0.0653, 0.3570, 0.1100, 0.2040, 0.0833, 0....
## $ valence                  <dbl> 0.518, 0.693, 0.613, 0.277, 0.725, 0.585, ...
## $ tempo                    <dbl> 122.036, 99.972, 124.008, 121.956, 123.976...
## $ duration_ms              <dbl> 194754, 162600, 176616, 169093, 189052, 16...
## $ release_year             <dbl> 2019, 2019, 2019, 2019, 2019, 2019, 2019, ...
## $ decade                   <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, ...
\end{verbatim}

\hypertarget{data-viz-by-artist}{%
\section{Data Viz by Artist}\label{data-viz-by-artist}}

QUESTION: Which artist (from just a few) is most popular? Does that change across different decades?

\hypertarget{explore-artist-info}{%
\subsection{Explore Artist Info}\label{explore-artist-info}}

Let's check who the artists are in this data set. Check what the unique values are for the \texttt{track\_artist} variable using \texttt{select()} and \texttt{unique()}.

\begin{verbatim}
## # A tibble: 10,693 x 1
##    track_artist    
##    <chr>           
##  1 Ed Sheeran      
##  2 Maroon 5        
##  3 Zara Larsson    
##  4 The Chainsmokers
##  5 Lewis Capaldi   
##  6 Katy Perry      
##  7 Sam Feldt       
##  8 Avicii          
##  9 Shawn Mendes    
## 10 Ellie Goulding  
## # ... with 10,683 more rows
\end{verbatim}

Who's the artist with the most songs? Use \texttt{count()} and \texttt{arrange()} to find out.

\begin{verbatim}
## # A tibble: 10,693 x 2
##    track_artist                  n
##    <chr>                     <int>
##  1 Martin Garrix               161
##  2 Queen                       136
##  3 The Chainsmokers            123
##  4 David Guetta                110
##  5 Don Omar                    102
##  6 Drake                       100
##  7 Dimitri Vegas & Like Mike    93
##  8 Calvin Harris                91
##  9 Hardwell                     84
## 10 Kygo                         83
## # ... with 10,683 more rows
\end{verbatim}

What genre are these artists classified as?

\begin{verbatim}
## # A tibble: 13,175 x 3
##    track_artist              playlist_genre     n
##    <chr>                     <chr>          <int>
##  1 Queen                     rock             134
##  2 Martin Garrix             edm              125
##  3 Don Omar                  latin            100
##  4 Dimitri Vegas & Like Mike edm               79
##  5 Guns N' Roses             rock              76
##  6 Hardwell                  edm               76
##  7 Logic                     rap               65
##  8 Daddy Yankee              latin             61
##  9 David Guetta              edm               60
## 10 Wisin & Yandel            latin             60
## # ... with 13,165 more rows
\end{verbatim}

What can we conclude about artist tracks and \texttt{playlist\_genre}?

Let's look at specific artist of our choosing. I'm looking at \texttt{The\ Cranberries}, \texttt{The\ Beatles} and \texttt{Queen}.
What genres are their songs classfied as?

\begin{verbatim}
## # A tibble: 4 x 3
##   track_artist    playlist_genre     n
##   <chr>           <chr>          <int>
## 1 Queen           pop                2
## 2 Queen           rock             134
## 3 The Beatles     rock              19
## 4 The Cranberries rock              45
\end{verbatim}

What are the two pop songs by Queen? Use \texttt{filter()} and \texttt{select()} to find out.

\begin{verbatim}
## # A tibble: 2 x 1
##   track_name                  
##   <chr>                       
## 1 Don't Stop Me Now - 2011 Mix
## 2 Radio Ga Ga
\end{verbatim}

\hypertarget{create-new-data-frame-with-selected-artists}{%
\subsection{Create new data frame with selected artists}\label{create-new-data-frame-with-selected-artists}}

Create another data frame that is a subset of the original \texttt{spotify\_songs} data frame to start visualizing info about the artists you chose.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# filter original data frame to create new data frame with selected artists}
\NormalTok{spotify_tc_tv_q <-}\StringTok{ }\NormalTok{spotify_songs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(track_artist }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'The Cranberries'}\NormalTok{, }\StringTok{'The Beatles'}\NormalTok{, }\StringTok{'Queen'}\NormalTok{))}

\CommentTok{# inspect new data frame}
\KeywordTok{glimpse}\NormalTok{(spotify_tc_tv_q)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 200
## Columns: 25
## $ track_id                 <chr> "7hQJA50XrCWABAu5v6QZ4i", "1lpFXKKckqVkyAN...
## $ track_name               <chr> "Don't Stop Me Now - 2011 Mix", "Radio Ga ...
## $ track_artist             <chr> "Queen", "Queen", "The Beatles", "The Cran...
## $ track_popularity         <dbl> 75, 3, 1, 43, 42, 44, 40, 40, 38, 37, 37, ...
## $ track_album_id           <chr> "21HMAUrbbYSj9NiPPlGumy", "39MMaY4ampwjkSO...
## $ track_album_name         <chr> "Jazz (Deluxe Remastered Version)", "The W...
## $ track_album_release_date <chr> "1978-11-10", "1984-02-27", "1996-03-18", ...
## $ playlist_name            <chr> "Dr. Q's Prescription Playlist\U0001f48a",...
## $ playlist_id              <chr> "6jAPdgY9XmxC9cgkXAVmVv", "65HtIbyFkaQPflC...
## $ playlist_genre           <chr> "pop", "pop", "rock", "rock", "rock", "roc...
## $ playlist_subgenre        <chr> "post-teen pop", "electropop", "album rock...
## $ danceability             <dbl> 0.563, 0.762, 0.388, 0.529, 0.473, 0.437, ...
## $ energy                   <dbl> 0.865, 0.414, 0.677, 0.845, 0.598, 0.785, ...
## $ key                      <dbl> 5, 5, 8, 0, 6, 4, 0, 9, 7, 9, 7, 0, 0, 9, ...
## $ loudness                 <dbl> -5.277, -12.036, -7.262, -5.432, -5.101, -...
## $ mode                     <dbl> 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...
## $ speechiness              <dbl> 0.1600, 0.0379, 0.0301, 0.0294, 0.0268, 0....
## $ acousticness             <dbl> 0.047200, 0.173000, 0.052700, 0.000199, 0....
## $ instrumentalness         <dbl> 1.91e-04, 1.11e-04, 1.07e-02, 1.74e-01, 7....
## $ liveness                 <dbl> 0.7700, 0.0942, 0.2210, 0.2270, 0.1250, 0....
## $ valence                  <dbl> 0.6010, 0.7310, 0.4240, 0.5710, 0.0565, 0....
## $ tempo                    <dbl> 156.271, 112.398, 175.818, 109.093, 93.022...
## $ duration_ms              <dbl> 209413, 349133, 234053, 256387, 239947, 25...
## $ release_year             <dbl> 1978, 1984, 1996, 2019, 2019, 2019, 2019, ...
## $ decade                   <dbl> 1970, 1980, 1990, 2010, 2010, 2010, 2010, ...
\end{verbatim}

\hypertarget{plotting}{%
\subsection{Plotting}\label{plotting}}

Plot song count (x) by \texttt{decade} (y) the songs were release across \texttt{track\_artist} (color). You need a \texttt{count} of \texttt{track\_artist} and \texttt{decade} for this plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ n, }\DataTypeTok{color =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-101-1.pdf}

To make tendencies clearer, we can add \texttt{geom\_line} to our plot. We need a new aesthetics for the lines to connect the right points, called \texttt{group}. In this case, \texttt{group} takes the same variable as the \texttt{color} mapping.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ n, }\DataTypeTok{color =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{group =}\NormalTok{ track_artist))}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-102-1.pdf}

From the plot above, what can we conclude about the selected artists? When did they start releasing songs?

Let's look at \texttt{track\_popularity} by artist across decade. For this, we need \texttt{group\_by} and \texttt{summarise} before we can build our plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ mean_popularity, }\DataTypeTok{color =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{group =}\NormalTok{ track_artist))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-103-1.pdf}

How would this plot look like as a bar plot?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ mean_popularity, }\DataTypeTok{fill =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{(}\DataTypeTok{position =} \StringTok{"dodge"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-104-1.pdf}

Which chart do you think is easier to read? Why?

We have multiple songs per artists, so we can include standard deviation in our \texttt{summarise}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity),}
            \DataTypeTok{sd_popularity =} \KeywordTok{sd}\NormalTok{(track_popularity))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 13 x 5
## # Groups:   track_artist [3]
##    track_artist    decade     n mean_popularity sd_popularity
##    <chr>            <dbl> <int>           <dbl>         <dbl>
##  1 Queen             1970    97            43.2         15.1 
##  2 Queen             1980    29            43.8         22.5 
##  3 Queen             1990     4            19.8         27.6 
##  4 Queen             2010     6            51.8         11.7 
##  5 The Beatles       1960     9            69.8          6.53
##  6 The Beatles       1970     5            69.2          5.89
##  7 The Beatles       1980     1            39           NA   
##  8 The Beatles       1990     1             1           NA   
##  9 The Beatles       2000     1            74           NA   
## 10 The Beatles       2010     2            55.5          4.95
## 11 The Cranberries   1990    31            52.5         13.3 
## 12 The Cranberries   2000     2            35.5          3.54
## 13 The Cranberries   2010    12            37.6         12.3
\end{verbatim}

NAs in our data frame is a problem. We can add \texttt{mutate} with \texttt{replace\_na} to replace these NAs with zero.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity),}
            \DataTypeTok{sd_popularity =} \KeywordTok{sd}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sd_popularity =} \KeywordTok{replace_na}\NormalTok{(sd_popularity, }\DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 13 x 5
## # Groups:   track_artist [3]
##    track_artist    decade     n mean_popularity sd_popularity
##    <chr>            <dbl> <int>           <dbl>         <dbl>
##  1 Queen             1970    97            43.2         15.1 
##  2 Queen             1980    29            43.8         22.5 
##  3 Queen             1990     4            19.8         27.6 
##  4 Queen             2010     6            51.8         11.7 
##  5 The Beatles       1960     9            69.8          6.53
##  6 The Beatles       1970     5            69.2          5.89
##  7 The Beatles       1980     1            39            0   
##  8 The Beatles       1990     1             1            0   
##  9 The Beatles       2000     1            74            0   
## 10 The Beatles       2010     2            55.5          4.95
## 11 The Cranberries   1990    31            52.5         13.3 
## 12 The Cranberries   2000     2            35.5          3.54
## 13 The Cranberries   2010    12            37.6         12.3
\end{verbatim}

The data frame looks good, let's add the plot code lines to the block of code above. This time, let's do a bar chart faceted by \texttt{track\_artist}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity),}
            \DataTypeTok{sd_popularity =} \KeywordTok{sd}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sd_popularity =} \KeywordTok{replace_na}\NormalTok{(sd_popularity, }\DecValTok{0}\NormalTok{),}
         \DataTypeTok{lower =}\NormalTok{ mean_popularity }\OperatorTok{-}\StringTok{ }\NormalTok{sd_popularity,}
         \DataTypeTok{upper =}\NormalTok{ mean_popularity }\OperatorTok{+}\StringTok{ }\NormalTok{sd_popularity)  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ mean_popularity, }\DataTypeTok{fill =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{track_artist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-107-1.pdf}

It looks the same as before. Let's add \texttt{geom\_errorbar} to it with \texttt{ymin} and \texttt{ymax} mappings. For that, we need to transform our data frame with \texttt{mutate} to calculate \texttt{lower} and \texttt{upper} variables, which represent the mean \textbf{minus} the standard deviation for the lower value of the range, and mean \textbf{plus} standard deviation for the upper value of the range.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity),}
            \DataTypeTok{sd_popularity =} \KeywordTok{sd}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sd_popularity =} \KeywordTok{replace_na}\NormalTok{(sd_popularity, }\DecValTok{0}\NormalTok{),}
         \DataTypeTok{lower =}\NormalTok{ mean_popularity }\OperatorTok{-}\StringTok{ }\NormalTok{sd_popularity,}
         \DataTypeTok{upper =}\NormalTok{ mean_popularity }\OperatorTok{+}\StringTok{ }\NormalTok{sd_popularity) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 13 x 7
## # Groups:   track_artist [3]
##    track_artist    decade     n mean_popularity sd_popularity lower upper
##    <chr>            <dbl> <int>           <dbl>         <dbl> <dbl> <dbl>
##  1 Queen             1970    97            43.2         15.1  28.0   58.3
##  2 Queen             1980    29            43.8         22.5  21.3   66.2
##  3 Queen             1990     4            19.8         27.6  -7.83  47.3
##  4 Queen             2010     6            51.8         11.7  40.2   63.5
##  5 The Beatles       1960     9            69.8          6.53 63.2   76.3
##  6 The Beatles       1970     5            69.2          5.89 63.3   75.1
##  7 The Beatles       1980     1            39            0    39     39  
##  8 The Beatles       1990     1             1            0     1      1  
##  9 The Beatles       2000     1            74            0    74     74  
## 10 The Beatles       2010     2            55.5          4.95 50.6   60.4
## 11 The Cranberries   1990    31            52.5         13.3  39.2   65.8
## 12 The Cranberries   2000     2            35.5          3.54 32.0   39.0
## 13 The Cranberries   2010    12            37.6         12.3  25.2   49.9
\end{verbatim}

Now we can use \texttt{geom\_errorbar}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity),}
            \DataTypeTok{sd_popularity =} \KeywordTok{sd}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sd_popularity =} \KeywordTok{replace_na}\NormalTok{(sd_popularity, }\DecValTok{0}\NormalTok{),}
         \DataTypeTok{lower =}\NormalTok{ mean_popularity }\OperatorTok{-}\StringTok{ }\NormalTok{sd_popularity,}
         \DataTypeTok{upper =}\NormalTok{ mean_popularity }\OperatorTok{+}\StringTok{ }\NormalTok{sd_popularity)  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ mean_popularity, }\DataTypeTok{fill =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ lower, }\DataTypeTok{ymax =}\NormalTok{ upper)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{track_artist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-109-1.pdf}

We can do a similar chart but look at the \texttt{2010} decade only.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(decade }\OperatorTok{==}\StringTok{ }\DecValTok{2010}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist, decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity),}
            \DataTypeTok{sd_popularity =} \KeywordTok{sd}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sd_popularity =} \KeywordTok{replace_na}\NormalTok{(sd_popularity, }\DecValTok{0}\NormalTok{),}
         \DataTypeTok{lower =}\NormalTok{ mean_popularity }\OperatorTok{-}\StringTok{ }\NormalTok{sd_popularity,}
         \DataTypeTok{upper =}\NormalTok{ mean_popularity }\OperatorTok{+}\StringTok{ }\NormalTok{sd_popularity)  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ track_artist, }\DataTypeTok{y =}\NormalTok{ mean_popularity, }\DataTypeTok{fill =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ lower, }\DataTypeTok{ymax =}\NormalTok{ upper)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{decade)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'track_artist' (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-110-1.pdf}

We can also collapse decade, and just look at popularity overall.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_tc_tv_q }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_artist) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity),}
            \DataTypeTok{sd_popularity =} \KeywordTok{sd}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sd_popularity =} \KeywordTok{replace_na}\NormalTok{(sd_popularity, }\DecValTok{0}\NormalTok{),}
         \DataTypeTok{lower =}\NormalTok{ mean_popularity }\OperatorTok{-}\StringTok{ }\NormalTok{sd_popularity,}
         \DataTypeTok{upper =}\NormalTok{ mean_popularity }\OperatorTok{+}\StringTok{ }\NormalTok{sd_popularity)  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ track_artist, }\DataTypeTok{y =}\NormalTok{ mean_popularity, }\DataTypeTok{fill =}\NormalTok{ track_artist)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_errorbar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ lower, }\DataTypeTok{ymax =}\NormalTok{ upper)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-111-1.pdf}

\hypertarget{data-viz-by-album}{%
\section{Data Viz by Album}\label{data-viz-by-album}}

QUESTION: Which Drake album is the most popular?

Let's review the steps to answer our question:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Create a new data frame that is a subset of our original data frame
\item
  Summarize and transform our new data frame to create the variables we need to plot the info we need
\item
  Try different plots until we find a plot that looks clear
\end{enumerate}

\hypertarget{create-new-data-frame}{%
\subsection{Create new data frame}\label{create-new-data-frame}}

We first filter our data frame by artist.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# filter original data frame to create new data frame with selected artists}
\NormalTok{spotify_drake <-}\StringTok{ }\NormalTok{spotify_songs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(track_artist }\OperatorTok{==}\StringTok{ 'Drake'}\NormalTok{)}

\CommentTok{# inspect new data frame}
\KeywordTok{glimpse}\NormalTok{(spotify_drake)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 100
## Columns: 25
## $ track_id                 <chr> "76P07ei8drjrenqtvDbefy", "1xznGGDReH1oQq0...
## $ track_name               <chr> "Hotline Bling", "One Dance", "Too Good", ...
## $ track_artist             <chr> "Drake", "Drake", "Drake", "Drake", "Drake...
## $ track_popularity         <dbl> 0, 20, 12, 72, 12, 10, 83, 83, 86, 68, 15,...
## $ track_album_id           <chr> "2e42oY2oFArkkTENT8UVXD", "3hARKC8cinq3mZL...
## $ track_album_name         <chr> "Views", "Views", "Views", "Thank Me Later...
## $ track_album_release_date <chr> "2016-05-06", "2016-05-06", "2016-05-06", ...
## $ playlist_name            <chr> "BALLARE - رقص", "Electropop Hits  2017-20...
## $ playlist_id              <chr> "1CMvQ4Yr5DlYvYzI0Vc2UE", "7kyvBmlc1uSqsTL...
## $ playlist_genre           <chr> "pop", "pop", "pop", "pop", "pop", "pop", ...
## $ playlist_subgenre        <chr> "post-teen pop", "electropop", "electropop...
## $ danceability             <dbl> 0.905, 0.791, 0.804, 0.431, 0.771, 0.893, ...
## $ energy                   <dbl> 0.617, 0.619, 0.648, 0.894, 0.629, 0.639, ...
## $ key                      <dbl> 2, 1, 7, 5, 1, 2, 1, 1, 7, 1, 11, 10, 2, 1...
## $ loudness                 <dbl> -8.039, -5.886, -7.805, -2.673, -5.790, -7...
## $ mode                     <dbl> 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, ...
## $ speechiness              <dbl> 0.0596, 0.0532, 0.1170, 0.3300, 0.0511, 0....
## $ acousticness             <dbl> 0.00287, 0.00784, 0.05730, 0.09510, 0.0080...
## $ instrumentalness         <dbl> 4.40e-04, 4.23e-03, 3.49e-05, 0.00e+00, 2....
## $ liveness                 <dbl> 0.0484, 0.3510, 0.1020, 0.1880, 0.3560, 0....
## $ valence                  <dbl> 0.572, 0.371, 0.392, 0.604, 0.362, 0.579, ...
## $ tempo                    <dbl> 134.972, 103.989, 117.983, 162.193, 103.91...
## $ duration_ms              <dbl> 267187, 173987, 263373, 258760, 173975, 26...
## $ release_year             <dbl> 2016, 2016, 2016, 2010, 2016, 2015, 2016, ...
## $ decade                   <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, ...
\end{verbatim}

What albums are there in this new data frame?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_drake }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(track_album_name) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\OperatorTok{-}\NormalTok{n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 27 x 2
##    track_album_name                                          n
##    <chr>                                                 <int>
##  1 Views                                                    23
##  2 Scorpion                                                 16
##  3 More Life                                                 9
##  4 The Best In The World Pack                                7
##  5 Take Care (Deluxe)                                        5
##  6 What A Time To Be Alive                                   5
##  7 If You're Reading This It's Too Late                      4
##  8 Care Package                                              3
##  9 Hotline Bling                                             3
## 10 Top Boy (A Selection of Music Inspired by the Series)     3
## # ... with 17 more rows
\end{verbatim}

\hypertarget{summarize-data}{%
\subsection{Summarize data}\label{summarize-data}}

Now we summarize our data for mean popularity per album.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_drake }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_album_name) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 27 x 2
##    track_album_name                     mean_popularity
##    <chr>                                          <dbl>
##  1 0 To 100 / The Catch Up                         5   
##  2 Back To Back                                   69   
##  3 Behind Barz (Bonus)                            74   
##  4 Care Package                                   61.3 
##  5 Fake Love                                       6   
##  6 Forever                                         2   
##  7 Hold On, We're Going Home                       1   
##  8 Hotline Bling                                   9.67
##  9 If You're Reading This It's Too Late           18   
## 10 More Life                                      47.9 
## # ... with 17 more rows
\end{verbatim}

\hypertarget{plot-summarized-data}{%
\subsection{Plot summarized data}\label{plot-summarized-data}}

We now add the \texttt{ggplot} code lines to our summarized data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_drake }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_album_name) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ track_album_name, }\DataTypeTok{x =}\NormalTok{ mean_popularity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-115-1.pdf}

Let's order the songs by \texttt{mean\_popularity}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_drake }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_album_name) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{reorder}\NormalTok{(track_album_name, mean_popularity), }\DataTypeTok{x =}\NormalTok{ mean_popularity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-116-1.pdf}

We can add labels to the bars, with the mean\_popularity for each album using \texttt{geom\_label}. A new mapping is needed for \texttt{label}, which is the same as the x mapping in this case.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_drake }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_album_name) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{reorder}\NormalTok{(track_album_name, mean_popularity), }\DataTypeTok{x =}\NormalTok{ mean_popularity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_label}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ mean_popularity))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-117-1.pdf}

We need to clean up the means. We can do that using \texttt{format}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_drake }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_album_name) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{reorder}\NormalTok{(track_album_name, mean_popularity), }\DataTypeTok{x =}\NormalTok{ mean_popularity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_label}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =} \KeywordTok{format}\NormalTok{(mean_popularity, }\DataTypeTok{digits =} \DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-118-1.pdf}

We can clean up our chart even more.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spotify_drake }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(track_album_name) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_popularity =} \KeywordTok{mean}\NormalTok{(track_popularity)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{reorder}\NormalTok{(track_album_name, mean_popularity), }\DataTypeTok{x =}\NormalTok{ mean_popularity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_label}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =} \KeywordTok{format}\NormalTok{(mean_popularity, }\DataTypeTok{digits =} \DecValTok{1}\NormalTok{))) }\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"mean popularity"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{""}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Albums by Drake"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-119-1.pdf}

\hypertarget{data-challenge-04}{%
\section{DATA CHALLENGE 04}\label{data-challenge-04}}

Accept \href{https://classroom.github.com/a/fYDB-CfS}{data challenge 04 assignment}

\hypertarget{data-case-study-1}{%
\chapter{Data Case Study 1}\label{data-case-study-1}}

This is our first case study of the semester. The goal of each case study is to consolidate the content we've covered so far in class, which at this point includes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Load libraries using \texttt{library()}
\item
  Read data using \texttt{read\_csv()} or \texttt{read\_excel()}
\item
  Inspect data using \texttt{summary()} or \texttt{glimpse()} and/or \texttt{View()}
\item
  Review your data question (what variables do you need to answer your question?)
\item
  Explore data using the following functions:
\end{enumerate}

\begin{itemize}
\item
  \texttt{count()}
\item
  \texttt{group\_by()} + \texttt{summarise()}
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Plot data using the functions above and:
\end{enumerate}

\begin{itemize}
\item
  \texttt{filter()}
\item
  \texttt{mutate()}
\item
  \texttt{gglot(aes())} + \texttt{geom\_...}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# load library}
\KeywordTok{library}\NormalTok{(tidyverse)}

\CommentTok{# read data in}
\NormalTok{olympic_events <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/olympic_history_athlete_events.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   ID = col_double(),
##   Name = col_character(),
##   Sex = col_character(),
##   Age = col_double(),
##   Height = col_double(),
##   Weight = col_double(),
##   Team = col_character(),
##   NOC = col_character(),
##   Games = col_character(),
##   Year = col_double(),
##   Season = col_character(),
##   City = col_character(),
##   Sport = col_character(),
##   Event = col_character(),
##   Medal = col_character()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{olympic_noc_regions <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/olympic_history_noc_regions.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   NOC = col_character(),
##   region = col_character(),
##   notes = col_character()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# inspect data }
\KeywordTok{glimpse}\NormalTok{(olympic_events)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 271,116
## Columns: 15
## $ ID     <dbl> 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, ...
## $ Name   <chr> "A Dijiang", "A Lamusi", "Gunnar Nielsen Aaby", "Edgar Linde...
## $ Sex    <chr> "M", "M", "M", "M", "F", "F", "F", "F", "F", "F", "M", "M", ...
## $ Age    <dbl> 24, 23, 24, 34, 21, 21, 25, 25, 27, 27, 31, 31, 31, 31, 33, ...
## $ Height <dbl> 180, 170, NA, NA, 185, 185, 185, 185, 185, 185, 188, 188, 18...
## $ Weight <dbl> 80, 60, NA, NA, 82, 82, 82, 82, 82, 82, 75, 75, 75, 75, 75, ...
## $ Team   <chr> "China", "China", "Denmark", "Denmark/Sweden", "Netherlands"...
## $ NOC    <chr> "CHN", "CHN", "DEN", "DEN", "NED", "NED", "NED", "NED", "NED...
## $ Games  <chr> "1992 Summer", "2012 Summer", "1920 Summer", "1900 Summer", ...
## $ Year   <dbl> 1992, 2012, 1920, 1900, 1988, 1988, 1992, 1992, 1994, 1994, ...
## $ Season <chr> "Summer", "Summer", "Summer", "Summer", "Winter", "Winter", ...
## $ City   <chr> "Barcelona", "London", "Antwerpen", "Paris", "Calgary", "Cal...
## $ Sport  <chr> "Basketball", "Judo", "Football", "Tug-Of-War", "Speed Skati...
## $ Event  <chr> "Basketball Men's Basketball", "Judo Men's Extra-Lightweight...
## $ Medal  <chr> NA, NA, NA, "Gold", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(olympic_noc_regions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 230
## Columns: 3
## $ NOC    <chr> "AFG", "AHO", "ALB", "ALG", "AND", "ANG", "ANT", "ANZ", "ARG...
## $ region <chr> "Afghanistan", "Curacao", "Albania", "Algeria", "Andorra", "...
## $ notes  <chr> NA, "Netherlands Antilles", NA, NA, NA, NA, "Antigua and Bar...
\end{verbatim}

\hypertarget{data-questions}{%
\section{Data Questions}\label{data-questions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Has athlete height and weight changed over time overall?
\item
  Has height and weight changed over time for the top 5 countries with the most medals?
\end{enumerate}

\hypertarget{data-exploration}{%
\section{Data Exploration}\label{data-exploration}}

Suggestions of data exploration:

What type of olympics? What years? How many athletes per game?

\begin{verbatim}
## # A tibble: 51 x 2
##    Games           n
##    <chr>       <int>
##  1 1896 Summer   380
##  2 1900 Summer  1936
##  3 1904 Summer  1301
##  4 1906 Summer  1733
##  5 1908 Summer  3101
##  6 1912 Summer  4040
##  7 1920 Summer  4292
##  8 1924 Summer  5233
##  9 1924 Winter   460
## 10 1928 Summer  4992
## # ... with 41 more rows
\end{verbatim}

This data set is huge, the plot below will take a while to process:
\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-122-1.pdf}

What are the top countries for medal count?

\begin{verbatim}
## # A tibble: 783 x 3
##    Team          Medal      n
##    <chr>         <chr>  <int>
##  1 United States Gold    2474
##  2 United States Silver  1512
##  3 United States Bronze  1233
##  4 Soviet Union  Gold    1058
##  5 Soviet Union  Silver   716
##  6 Germany       Gold     679
##  7 Germany       Bronze   678
##  8 Soviet Union  Bronze   677
##  9 Germany       Silver   627
## 10 Great Britain Silver   582
## # ... with 773 more rows
\end{verbatim}

\hypertarget{calculate-height-and-weight-relationship}{%
\section{Calculate height and weight relationship}\label{calculate-height-and-weight-relationship}}

It's difficult to plot three numeric variables (in this case we want to plot weight, height, across different years) with so many data points. So I'll create a new variable in my data frame with is the relationship between height and weight (i.e., kg per cm).

\begin{verbatim}
## # A tibble: 271,116 x 3
##    Weight Height kg_per_cm
##     <dbl>  <dbl>     <dbl>
##  1     80    180     0.444
##  2     60    170     0.353
##  3     NA     NA    NA    
##  4     NA     NA    NA    
##  5     82    185     0.443
##  6     82    185     0.443
##  7     82    185     0.443
##  8     82    185     0.443
##  9     82    185     0.443
## 10     82    185     0.443
## # ... with 271,106 more rows
\end{verbatim}

\hypertarget{plot-kilos-per-centimeter-across-years}{%
\section{Plot kilos per centimeter across years}\label{plot-kilos-per-centimeter-across-years}}

Now that we have this new variable, which is kilos per centimeters, we can plot this variable across years.

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-125-1.pdf}

Let's see if summarised data (i.e., mean of kg\_per\_cm across year), makes more sense.

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-126-1.pdf}

Let's split by Summer vs.~Winter olympics.

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-127-1.pdf}

\hypertarget{plot-weight-over-time}{%
\section{Plot weight over time}\label{plot-weight-over-time}}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-128-1.pdf}

\hypertarget{plot-height-over-time}{%
\section{Plot height over time}\label{plot-height-over-time}}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-129-1.pdf}

\hypertarget{data-filtering}{%
\section{Data Filtering}\label{data-filtering}}

Get only top 5 countries for highest medal count

\begin{verbatim}
## # A tibble: 5 x 2
##   Team              n
##   <chr>         <int>
## 1 United States  5219
## 2 Soviet Union   2451
## 3 Germany        1984
## 4 Great Britain  1673
## 5 France         1550
\end{verbatim}

Create a list of these countries to filter the largest data set to create a smaller data frame.

\begin{verbatim}
## Rows: 56,100
## Columns: 16
## $ ID        <dbl> 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 34, 52, 5...
## $ Name      <chr> "Per Knut Aaland", "Per Knut Aaland", "Per Knut Aaland", ...
## $ Sex       <chr> "M", "M", "M", "M", "M", "M", "M", "M", "M", "M", "M", "M...
## $ Age       <dbl> 31, 31, 31, 31, 33, 33, 33, 33, 31, 31, 31, 31, 33, 33, 3...
## $ Height    <dbl> 188, 188, 188, 188, 188, 188, 188, 188, 183, 183, 183, 18...
## $ Weight    <dbl> 75, 75, 75, 75, 75, 75, 75, 75, 72, 72, 72, 72, 72, 72, 7...
## $ Team      <chr> "United States", "United States", "United States", "Unite...
## $ NOC       <chr> "USA", "USA", "USA", "USA", "USA", "USA", "USA", "USA", "...
## $ Games     <chr> "1992 Winter", "1992 Winter", "1992 Winter", "1992 Winter...
## $ Year      <dbl> 1992, 1992, 1992, 1992, 1994, 1994, 1994, 1994, 1992, 199...
## $ Season    <chr> "Winter", "Winter", "Winter", "Winter", "Winter", "Winter...
## $ City      <chr> "Albertville", "Albertville", "Albertville", "Albertville...
## $ Sport     <chr> "Cross Country Skiing", "Cross Country Skiing", "Cross Co...
## $ Event     <chr> "Cross Country Skiing Men's 10 kilometres", "Cross Countr...
## $ Medal     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ kg_per_cm <dbl> 0.3989362, 0.3989362, 0.3989362, 0.3989362, 0.3989362, 0....
\end{verbatim}

\hypertarget{plot-height-and-weight-across-countries-over-the-years}{%
\section{Plot height and weight across countries over the years}\label{plot-height-and-weight-across-countries-over-the-years}}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-132-1.pdf}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-133-1.pdf}

\hypertarget{solving-the-problem-of-team-name-changes-over-time}{%
\section{Solving the problem of team name changes over time}\label{solving-the-problem-of-team-name-changes-over-time}}

We can use name of Olympic committee (\texttt{NOC}) to standardized Team to country

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{olympic_events }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(NOC, Team)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,231 x 3
##    NOC   Team                     n
##    <chr> <chr>                <int>
##  1 AFG   Afghanistan            126
##  2 AHO   Netherlands Antilles    79
##  3 ALB   Albania                 70
##  4 ALG   Algeria                551
##  5 AND   Andorra                169
##  6 ANG   Angola                 267
##  7 ANT   Antigua and Barbuda    133
##  8 ANZ   Australasia             77
##  9 ANZ   Sydney Rowing Club       9
## 10 ARG   Acturus                  2
## # ... with 1,221 more rows
\end{verbatim}

The \texttt{olympic\_noc\_regions} data frame can help with that process.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(olympic_noc_regions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   NOC   region      notes               
##   <chr> <chr>       <chr>               
## 1 AFG   Afghanistan <NA>                
## 2 AHO   Curacao     Netherlands Antilles
## 3 ALB   Albania     <NA>                
## 4 ALG   Algeria     <NA>                
## 5 AND   Andorra     <NA>                
## 6 ANG   Angola      <NA>
\end{verbatim}

We can add region to our \texttt{olympic\_events} data frame by joining the \texttt{olympic\_events} data frame with the \texttt{olympic\_noc\_regions} data frame by the \texttt{NOC} column. For that we will use the \texttt{left\_join()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{olympic_events <-}\StringTok{ }\KeywordTok{left_join}\NormalTok{(olympic_events,}
\NormalTok{                       olympic_noc_regions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "NOC"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{olympic_events }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(NOC, region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 230 x 3
##    NOC   region          n
##    <chr> <chr>       <int>
##  1 AFG   Afghanistan   126
##  2 AHO   Curacao        79
##  3 ALB   Albania        70
##  4 ALG   Algeria       551
##  5 AND   Andorra       169
##  6 ANG   Angola        267
##  7 ANT   Antigua       133
##  8 ANZ   Australia      86
##  9 ARG   Argentina    3297
## 10 ARM   Armenia       221
## # ... with 220 more rows
\end{verbatim}

Let's check what we have for Russia now.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{olympic_events }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(region }\OperatorTok{==}\StringTok{ "Russia"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(NOC, region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##   NOC   region     n
##   <chr> <chr>  <int>
## 1 EUN   Russia   864
## 2 RUS   Russia  5143
## 3 URS   Russia  5685
\end{verbatim}

We can now calculate medals per region instead of team name.
Get only top 5 countries for highest medal count

\begin{verbatim}
## # A tibble: 5 x 2
##   region      n
##   <chr>   <int>
## 1 USA      5637
## 2 Russia   3947
## 3 Germany  3756
## 4 UK       2068
## 5 France   1777
\end{verbatim}

\hypertarget{data-challenge-05}{%
\section{DATA CHALLENGE 05}\label{data-challenge-05}}

Accept \href{https://classroom.github.com/a/6eey650g}{data challenge 05 assignment}

\hypertarget{data-case-study-2}{%
\chapter{Data Case Study 2}\label{data-case-study-2}}

We've been working mainly with the \texttt{tidyverse} library, but today we will work with a few different libraries. The packages \texttt{janitor} and \texttt{lubridate} are very useful. Maybe sure you have these installed (use \texttt{install.packages}) before you load these libraries.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(janitor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'janitor'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     chisq.test, fisher.test
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\hypertarget{reading-data-from-a-url}{%
\section{Reading data from a URL}\label{reading-data-from-a-url}}

Today we are working with a large data set on global land temperatures. I added the csv file to github because it's a very large file. You can use \texttt{read\_csv} to read the file directly from github

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{global_temperatures <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://raw.githubusercontent.com/esoc214/fall2020_002_class_scripts/main/data/GlobalLandTemperaturesByCountry.csv"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   dt = col_date(format = ""),
##   AverageTemperature = col_double(),
##   AverageTemperatureUncertainty = col_double(),
##   Country = col_character()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# inspect data}
\KeywordTok{glimpse}\NormalTok{(global_temperatures)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 577,462
## Columns: 4
## $ dt                            <date> 1743-11-01, 1743-12-01, 1744-01-01, ...
## $ AverageTemperature            <dbl> 4.384, NA, NA, NA, NA, 1.530, 6.702, ...
## $ AverageTemperatureUncertainty <dbl> 2.294, NA, NA, NA, NA, 4.680, 1.789, ...
## $ Country                       <chr> "Åland", "Åland", "Åland", "Åland", "...
\end{verbatim}

\hypertarget{cleaning-up-column-names}{%
\section{Cleaning up column names}\label{cleaning-up-column-names}}

Column names from different data sets usually have a number of different casings (Camel, Pascal, Snake, Kebab Case, etc.). I like to use \texttt{clean\_names()} to standardize column names to \texttt{snake\_case}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{global_temperatures <-}\StringTok{ }\NormalTok{global_temperatures }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{clean_names}\NormalTok{()}

\CommentTok{# inspect data}
\KeywordTok{glimpse}\NormalTok{(global_temperatures)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 577,462
## Columns: 4
## $ dt                              <date> 1743-11-01, 1743-12-01, 1744-01-01...
## $ average_temperature             <dbl> 4.384, NA, NA, NA, NA, 1.530, 6.702...
## $ average_temperature_uncertainty <dbl> 2.294, NA, NA, NA, NA, 4.680, 1.789...
## $ country                         <chr> "Åland", "Åland", "Åland", "Åland",...
\end{verbatim}

\hypertarget{manipulating-dates}{%
\section{Manipulating Dates}\label{manipulating-dates}}

Now, let's turn our attention to the \texttt{dt} column, which is a date.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(global_temperatures}\OperatorTok{$}\NormalTok{dt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Date"
\end{verbatim}

There's a number of functions we can run on a \texttt{Date} variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# extract year from dt variable in global_temperatures}
\KeywordTok{year}\NormalTok{(global_temperatures}\OperatorTok{$}\NormalTok{dt)[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1743 1743 1744 1744 1744 1744 1744 1744 1744 1744
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# extract month from dt variable in global_temperatures}
\KeywordTok{month}\NormalTok{(global_temperatures}\OperatorTok{$}\NormalTok{dt)[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 11 12  1  2  3  4  5  6  7  8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{month}\NormalTok{(global_temperatures}\OperatorTok{$}\NormalTok{dt, }\DataTypeTok{label =} \OtherTok{TRUE}\NormalTok{)[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] Nov Dec Jan Feb Mar Apr May Jun Jul Aug
## 12 Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < Sep < ... < Dec
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# extract week from dt variable in global_temperatures}
\KeywordTok{week}\NormalTok{(global_temperatures}\OperatorTok{$}\NormalTok{dt)[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 44 48  1  5  9 14 18 22 27 31
\end{verbatim}

We can create new columns in our data frame with \texttt{year}, \texttt{month}, and \texttt{week} extracted from \texttt{dt} in our data frame by using \texttt{mutate}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{global_temperatures }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{year =} \KeywordTok{year}\NormalTok{(dt),}
         \DataTypeTok{month =} \KeywordTok{month}\NormalTok{(dt),}
         \DataTypeTok{decade =}\NormalTok{ year }\OperatorTok{-}\StringTok{ }\NormalTok{(year }\OperatorTok{%%}\StringTok{ }\DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 577,462 x 7
##    dt         average_temperat~ average_temperature_~ country  year month decade
##    <date>                 <dbl>                 <dbl> <chr>   <dbl> <dbl>  <dbl>
##  1 1743-11-01              4.38                  2.29 Åland    1743    11   1740
##  2 1743-12-01             NA                    NA    Åland    1743    12   1740
##  3 1744-01-01             NA                    NA    Åland    1744     1   1740
##  4 1744-02-01             NA                    NA    Åland    1744     2   1740
##  5 1744-03-01             NA                    NA    Åland    1744     3   1740
##  6 1744-04-01              1.53                  4.68 Åland    1744     4   1740
##  7 1744-05-01              6.70                  1.79 Åland    1744     5   1740
##  8 1744-06-01             11.6                   1.58 Åland    1744     6   1740
##  9 1744-07-01             15.3                   1.41 Åland    1744     7   1740
## 10 1744-08-01             NA                    NA    Åland    1744     8   1740
## # ... with 577,452 more rows
\end{verbatim}

Instead of just printing to the console, let's change the original data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{global_temperatures <-}\StringTok{ }\NormalTok{global_temperatures }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{year =} \KeywordTok{year}\NormalTok{(dt),}
         \DataTypeTok{month =} \KeywordTok{month}\NormalTok{(dt),}
         \DataTypeTok{decade =} \KeywordTok{gsub}\NormalTok{(}\StringTok{"([12][0-9][0-9])[0-9]"}\NormalTok{, }\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{10"}\NormalTok{, year))}

\CommentTok{# inspect changes}
\KeywordTok{glimpse}\NormalTok{(global_temperatures)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 577,462
## Columns: 7
## $ dt                              <date> 1743-11-01, 1743-12-01, 1744-01-01...
## $ average_temperature             <dbl> 4.384, NA, NA, NA, NA, 1.530, 6.702...
## $ average_temperature_uncertainty <dbl> 2.294, NA, NA, NA, NA, 4.680, 1.789...
## $ country                         <chr> "Åland", "Åland", "Åland", "Åland",...
## $ year                            <dbl> 1743, 1743, 1744, 1744, 1744, 1744,...
## $ month                           <dbl> 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...
## $ decade                          <chr> "1740", "1740", "1740", "1740", "17...
\end{verbatim}

\hypertarget{extra-data-libraries}{%
\section{Extra Data libraries}\label{extra-data-libraries}}

If you need some hierarchical information that is not present in your data frame, such as continent based on country, check if there is a package that will do that for you. In our case, we will use the \texttt{countrycode} package.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# make sure you install this library}
\KeywordTok{library}\NormalTok{(countrycode)}
\end{Highlighting}
\end{Shaded}

Let's look at our \texttt{country} variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# what does country look like in our data?}
\NormalTok{global_temperatures }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(country)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 243 x 2
##    country            n
##    <chr>          <int>
##  1 Afghanistan     2106
##  2 Africa          1965
##  3 Åland           3239
##  4 Albania         3239
##  5 Algeria         2721
##  6 American Samoa  1761
##  7 Andorra         3239
##  8 Angola          1878
##  9 Anguilla        2277
## 10 Antarctica       764
## # ... with 233 more rows
\end{verbatim}

We use the function \texttt{countrycode()} to get continent from a country name.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create new column called continent}
\NormalTok{global_temperatures <-}\StringTok{ }\NormalTok{global_temperatures }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{continent =} \KeywordTok{countrycode}\NormalTok{(}\DataTypeTok{sourcevar =}\NormalTok{ country,}
                            \DataTypeTok{origin =} \StringTok{"country.name"}\NormalTok{,}
                            \DataTypeTok{destination =} \StringTok{"continent"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Problem with `mutate()` input `continent`.
## i Some values were not matched unambiguously: Africa, Antarctica, Asia, Baker Island, Europe, French Southern And Antarctic Lands, Heard Island And Mcdonald Islands, Kingman Reef, North America, Oceania, Palmyra Atoll, Saint Martin, South America, South Georgia And The South Sandwich Isla, Virgin Islands
## 
## i Input `continent` is `countrycode(sourcevar = country, origin = "country.name", destination = "continent")`.
\end{verbatim}

\begin{verbatim}
## Warning in countrycode(sourcevar = country, origin = "country.name", destination = "continent"): Some values were not matched unambiguously: Africa, Antarctica, Asia, Baker Island, Europe, French Southern And Antarctic Lands, Heard Island And Mcdonald Islands, Kingman Reef, North America, Oceania, Palmyra Atoll, Saint Martin, South America, South Georgia And The South Sandwich Isla, Virgin Islands
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# inspect data}
\KeywordTok{glimpse}\NormalTok{(global_temperatures)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 577,462
## Columns: 8
## $ dt                              <date> 1743-11-01, 1743-12-01, 1744-01-01...
## $ average_temperature             <dbl> 4.384, NA, NA, NA, NA, 1.530, 6.702...
## $ average_temperature_uncertainty <dbl> 2.294, NA, NA, NA, NA, 4.680, 1.789...
## $ country                         <chr> "Åland", "Åland", "Åland", "Åland",...
## $ year                            <dbl> 1743, 1743, 1744, 1744, 1744, 1744,...
## $ month                           <dbl> 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...
## $ decade                          <chr> "1740", "1740", "1740", "1740", "17...
## $ continent                       <chr> "Europe", "Europe", "Europe", "Euro...
\end{verbatim}

Always check your data. Let's look at continent more closely, especially since we got a warning message.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# why some continents were not assigned}
\NormalTok{global_temperatures }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(continent)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{distinct}\NormalTok{(country)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 15 x 1
##    country                                  
##    <chr>                                    
##  1 Africa                                   
##  2 Antarctica                               
##  3 Asia                                     
##  4 Baker Island                             
##  5 Europe                                   
##  6 French Southern And Antarctic Lands      
##  7 Heard Island And Mcdonald Islands        
##  8 Kingman Reef                             
##  9 North America                            
## 10 Oceania                                  
## 11 Palmyra Atoll                            
## 12 Saint Martin                             
## 13 South America                            
## 14 South Georgia And The South Sandwich Isla
## 15 Virgin Islands
\end{verbatim}

It seems we can eliminate the rows with NA for continent.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# keep only continents that are not NA}
\NormalTok{global_temp_continents <-}\StringTok{ }\NormalTok{global_temperatures }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(continent))}
\end{Highlighting}
\end{Shaded}

\hypertarget{exploring-data}{%
\section{Exploring Data}\label{exploring-data}}

Now that our data is clean and transformed, what's our data question? The data frame is still very large, so some summarization would be helpful.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{global_temp_continents  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(decade, continent) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_temp =} \KeywordTok{mean}\NormalTok{(average_temperature, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'decade' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 128 x 3
## # Groups:   decade [28]
##    decade continent mean_temp
##    <chr>  <chr>         <dbl>
##  1 1740   Americas       2.62
##  2 1740   Europe         6.98
##  3 1750   Africa        19.8 
##  4 1750   Americas       7.30
##  5 1750   Europe         8.53
##  6 1760   Africa        19.8 
##  7 1760   Americas       6.44
##  8 1760   Europe         8.31
##  9 1770   Africa        20.1 
## 10 1770   Americas       6.61
## # ... with 118 more rows
\end{verbatim}

It's still a long data frame, plotting helps here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{global_temp_continents  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(decade, continent) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_temp =} \KeywordTok{mean}\NormalTok{(average_temperature, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ mean_temp, }\DataTypeTok{color =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'decade' (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-151-1.pdf}

Looking at the plot above, how reliable do you think these temperatures are? Why?

Let's look at Europe only.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{europe_temps <-}\StringTok{ }\NormalTok{global_temp_continents  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Europe"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{europe_temps  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(decade) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_temp =} \KeywordTok{mean}\NormalTok{(average_temperature, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ decade, }\DataTypeTok{y =}\NormalTok{ mean_temp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-153-1.pdf}

Now that we have filtered by continent, we can look at \texttt{year} instead of \texttt{decade}, because you have less information to plot (just one continent).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{europe_temps  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_temp =} \KeywordTok{mean}\NormalTok{(average_temperature, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ mean_temp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## Warning: Removed 4 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-154-1.pdf}

Let's look at monthly temperatures

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{europe_temps  }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(month) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_temp =} \KeywordTok{mean}\NormalTok{(average_temperature, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ month, }\DataTypeTok{y =}\NormalTok{ mean_temp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-155-1.pdf}

Would this pattern, of temperature increase around June, be the same no matter the continent?

\hypertarget{data-challenge-06}{%
\section{DATA CHALLENGE 06}\label{data-challenge-06}}

Accept \href{https://classroom.github.com/a/6RuMwg7C}{data challenge 06 assignment}

\hypertarget{getting-data}{%
\chapter{Getting Data}\label{getting-data}}

\hypertarget{search-for-data-sets}{%
\section{Search for data sets}\label{search-for-data-sets}}

There are number of websites that are repositories of data sets. Here's a list of some resources:

\begin{itemize}
\item
  Kaggle Data Sets \url{https://www.kaggle.com/datasets}
\item
  Google Dataset Search \url{https://datasetsearch.research.google.com/}
\item
  U.S. Department of Education Public Data Listing \url{https://www2.ed.gov/about/data/list.html}
\item
  US Department of Health and Human Services, Datasets \& Research Resources \url{https://www.nichd.nih.gov/research/resources/index}
\item
  City of Tucson Open Data \url{https://gisdata.tucsonaz.gov/}
\end{itemize}

\hypertarget{extracting-data-tables-from-pdf-files}{%
\section{Extracting data tables from pdf files}\label{extracting-data-tables-from-pdf-files}}

Many times you won't have access to an actual data file. Many institutions make data available in pdf format. Lucky for us, there's an R package to extract tables from pdf files.

As usual, we need to install the package first.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"tabulizer"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Remember we need to install a package only once (and updated it once in a while), but every time we want to use it, we need to call it with the \texttt{library()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tabulizer)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(janitor)}
\end{Highlighting}
\end{Shaded}

Let's look at UArizona's \href{https://uair.arizona.edu/CommonDataSet}{Common Data Set} website.

For this lesson we will focus on the \href{https://uair.arizona.edu/sites/default/files/2019-2020\%20CDS_FINAL_060820.pdf}{Common Data Set 2019-2020}

First we need to run the \texttt{extract\_tables()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ua_common_dataset <-}\StringTok{ }\KeywordTok{extract_tables}\NormalTok{(}\StringTok{"https://uair.arizona.edu/sites/default/files/2019-2020%20CDS_FINAL_060820.pdf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{extract\_tables()} function returns a list with all tables that it was able to extract from the pdf file given.

Let's take a look at the seventh table in the list.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ua_common_dataset[[}\DecValTok{9}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       [,1] [,2]                              [,3]   
##  [1,] "B3" "Certificate/diploma"             "1 28" 
##  [2,] "B3" "Associate degrees"               "-"    
##  [3,] "B3" "Bachelor's degrees"              "7,754"
##  [4,] "B3" "Postbachelor's certificates"     "172"  
##  [5,] "B3" "Master's degrees"                "2,100"
##  [6,] "B3" "Post-Master's certificates"      "9"    
##  [7,] "B3" "Doctoral degrees –"              "448"  
##  [8,] ""   "research/scholarship"            ""     
##  [9,] "B3" "Doctoral degrees – professional" "533"  
## [10,] ""   "practice"                        ""     
## [11,] "B3" "Doctoral degrees – other"        "-"
\end{verbatim}

It's pretty messy. We can start by converting it to an actual data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{enrollment_data <-}\StringTok{ }\NormalTok{ua_common_dataset[[}\DecValTok{9}\NormalTok{]] }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{as.data.frame}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{clean_names}\NormalTok{()}

\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    v1                              v2    v3
## 1  B3             Certificate/diploma  1 28
## 2  B3               Associate degrees     -
## 3  B3              Bachelor's degrees 7,754
## 4  B3     Postbachelor's certificates   172
## 5  B3                Master's degrees 2,100
## 6  B3      Post-Master's certificates     9
## 7  B3              Doctoral degrees –   448
## 8                research/scholarship      
## 9  B3 Doctoral degrees – professional   533
## 10                           practice      
## 11 B3        Doctoral degrees – other     -
\end{verbatim}

We don't need the first column

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{enrollment_data <-}\StringTok{ }\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{v1)}

\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                 v2    v3
## 1              Certificate/diploma  1 28
## 2                Associate degrees     -
## 3               Bachelor's degrees 7,754
## 4      Postbachelor's certificates   172
## 5                 Master's degrees 2,100
## 6       Post-Master's certificates     9
## 7               Doctoral degrees –   448
## 8             research/scholarship      
## 9  Doctoral degrees – professional   533
## 10                        practice      
## 11        Doctoral degrees – other     -
\end{verbatim}

We can manually change the column names.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colnames}\NormalTok{(enrollment_data) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "v2" "v3"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colnames}\NormalTok{(enrollment_data) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"type"}\NormalTok{, }
                               \StringTok{"count"}\NormalTok{)}

\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                               type count
## 1              Certificate/diploma  1 28
## 2                Associate degrees     -
## 3               Bachelor's degrees 7,754
## 4      Postbachelor's certificates   172
## 5                 Master's degrees 2,100
## 6       Post-Master's certificates     9
## 7               Doctoral degrees –   448
## 8             research/scholarship      
## 9  Doctoral degrees – professional   533
## 10                        practice      
## 11        Doctoral degrees – other     -
\end{verbatim}

We can now delete empty rows (which comes from line breaks in the table, you can fix these further if you think it's needed).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# remove empty rows}
\NormalTok{enrollment_data <-}\StringTok{ }\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(count }\OperatorTok{!=}\StringTok{ ""}\NormalTok{)}

\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                              type count
## 1             Certificate/diploma  1 28
## 2               Associate degrees     -
## 3              Bachelor's degrees 7,754
## 4     Postbachelor's certificates   172
## 5                Master's degrees 2,100
## 6      Post-Master's certificates     9
## 7              Doctoral degrees –   448
## 8 Doctoral degrees – professional   533
## 9        Doctoral degrees – other     -
\end{verbatim}

We can replace \texttt{-} with zero.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# replace - with 0}
\NormalTok{enrollment_data <-}\StringTok{ }\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{count =} \KeywordTok{ifelse}\NormalTok{(count }\OperatorTok{==}\StringTok{ "-"}\NormalTok{,}
                        \DecValTok{0}\NormalTok{, count))}

\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                              type count
## 1             Certificate/diploma  1 28
## 2               Associate degrees     0
## 3              Bachelor's degrees 7,754
## 4     Postbachelor's certificates   172
## 5                Master's degrees 2,100
## 6      Post-Master's certificates     9
## 7              Doctoral degrees –   448
## 8 Doctoral degrees – professional   533
## 9        Doctoral degrees – other     0
\end{verbatim}

Finally, we convert \texttt{count} to number.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# try parse_number}
\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{count =} \KeywordTok{parse_number}\NormalTok{(count))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                              type count
## 1             Certificate/diploma     1
## 2               Associate degrees     0
## 3              Bachelor's degrees  7754
## 4     Postbachelor's certificates   172
## 5                Master's degrees  2100
## 6      Post-Master's certificates     9
## 7              Doctoral degrees –   448
## 8 Doctoral degrees – professional   533
## 9        Doctoral degrees – other     0
\end{verbatim}

Remove spaces between numbers.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# use gsub to remove spaces (i.e., replace \textbackslash{}\textbackslash{}s with nothing)}
\NormalTok{enrollment_data <-}\StringTok{ }\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{count =} \KeywordTok{gsub}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{s"}\NormalTok{, }\StringTok{""}\NormalTok{, count))}

\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                              type count
## 1             Certificate/diploma   128
## 2               Associate degrees     0
## 3              Bachelor's degrees 7,754
## 4     Postbachelor's certificates   172
## 5                Master's degrees 2,100
## 6      Post-Master's certificates     9
## 7              Doctoral degrees –   448
## 8 Doctoral degrees – professional   533
## 9        Doctoral degrees – other     0
\end{verbatim}

Try parse\_number again

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# try parse_number}
\NormalTok{enrollment_data <-}\StringTok{ }\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{count =} \KeywordTok{parse_number}\NormalTok{(count))}

\CommentTok{# check data}
\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                              type count
## 1             Certificate/diploma   128
## 2               Associate degrees     0
## 3              Bachelor's degrees  7754
## 4     Postbachelor's certificates   172
## 5                Master's degrees  2100
## 6      Post-Master's certificates     9
## 7              Doctoral degrees –   448
## 8 Doctoral degrees – professional   533
## 9        Doctoral degrees – other     0
\end{verbatim}

We can add info about year, and then process all the other pdf files.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# try parse_number}
\NormalTok{enrollment_data <-}\StringTok{ }\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{year =} \DecValTok{2019}\NormalTok{)}

\CommentTok{# check data}
\NormalTok{enrollment_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                              type count year
## 1             Certificate/diploma   128 2019
## 2               Associate degrees     0 2019
## 3              Bachelor's degrees  7754 2019
## 4     Postbachelor's certificates   172 2019
## 5                Master's degrees  2100 2019
## 6      Post-Master's certificates     9 2019
## 7              Doctoral degrees –   448 2019
## 8 Doctoral degrees – professional   533 2019
## 9        Doctoral degrees – other     0 2019
\end{verbatim}

We can now plot the data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# draw bar plot per type of degree}
\NormalTok{enrollment_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ count,}
             \DataTypeTok{y =} \KeywordTok{reorder}\NormalTok{(type, count))) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'Doctoral degrees – other' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees –' in 'mbcsToSbcs': dot substituted for
## <93>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <e2>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <80>
\end{verbatim}

\begin{verbatim}
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'Doctoral degrees – professional' in 'mbcsToSbcs': dot
## substituted for <93>
\end{verbatim}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-169-1.pdf}

\hypertarget{extracting-data-tables-from-websites}{%
\section{Extracting data tables from websites}\label{extracting-data-tables-from-websites}}

Other times you will find data available in webpages, or in HTML format. Lucky for us again, there's an R package to extract tables from html files.

As usual, we need to install the package first.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"rvest"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Remember we need to install a package only once (and updated it once in a while), but every time we want to use it, we need to call it with the \texttt{library()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(rvest)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: xml2
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'rvest'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:purrr':
## 
##     pluck
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:readr':
## 
##     guess_encoding
\end{verbatim}

Let's check what tables there are in \href{https://en.wikipedia.org/wiki/University_of_Arizona}{UArizona's wikipedia page}.

First, we need to read in the html file.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uarizona_wiki_html <-}\StringTok{ }\KeywordTok{read_html}\NormalTok{(}\StringTok{"https://en.wikipedia.org/wiki/University_of_Arizona"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We now parse the html for tables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uarizona_wiki_html }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{html_nodes}\NormalTok{(}\StringTok{"table"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {xml_nodeset (19)}
##  [1] <table class="infobox vcard" style="width:22em">\n<caption class="fn org ...
##  [2] <table class="multicol" role="presentation" style="border-collapse: coll ...
##  [3] <table class="infobox" style="width: 22em"><tbody>\n<tr><th colspan="2"  ...
##  [4] <table class="wikitable sortable collapsible collapsed" style="float:rig ...
##  [5] <table class="wikitable sortable collapsible collapsed" style="float:rig ...
##  [6] <table style="float:right; font-size:85%; margin:10px" class="wikitable" ...
##  [7] <table role="presentation" class="mbox-small plainlinks sistersitebox" s ...
##  [8] <table class="nowraplinks hlist mw-collapsible mw-collapsed navbox-inner ...
##  [9] <table class="nowraplinks mw-collapsible mw-collapsed navbox-inner" styl ...
## [10] <table class="nowraplinks mw-collapsible mw-collapsed navbox-inner" styl ...
## [11] <table class="nowraplinks mw-collapsible autocollapse navbox-inner" styl ...
## [12] <table class="nowraplinks mw-collapsible autocollapse navbox-inner" styl ...
## [13] <table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbo ...
## [14] <table class="nowraplinks mw-collapsible autocollapse navbox-inner" styl ...
## [15] <table class="nowraplinks mw-collapsible autocollapse navbox-inner" styl ...
## [16] <table class="nowraplinks mw-collapsible autocollapse navbox-inner" styl ...
## [17] <table class="nowraplinks mw-collapsible autocollapse navbox-inner" styl ...
## [18] <table class="nowraplinks mw-collapsible autocollapse navbox-inner" styl ...
## [19] <table class="nowraplinks hlist navbox-inner" style="border-spacing:0;ba ...
\end{verbatim}

Too many tables. We can be specific, and retrieve nodes per class.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uarizona_wiki_html }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{html_nodes}\NormalTok{(}\StringTok{".wikitable"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {xml_nodeset (3)}
## [1] <table class="wikitable sortable collapsible collapsed" style="float:righ ...
## [2] <table class="wikitable sortable collapsible collapsed" style="float:righ ...
## [3] <table style="float:right; font-size:85%; margin:10px" class="wikitable"> ...
\end{verbatim}

This looks a little better.

It looks like the table we want is the third table.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create wiki_tables object}
\NormalTok{wiki_tables <-}\StringTok{ }\NormalTok{uarizona_wiki_html }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{html_nodes}\NormalTok{(}\StringTok{".wikitable"}\NormalTok{)}

\CommentTok{# transform node into an actual table}
\NormalTok{fall_freshman_stats <-}\StringTok{ }\NormalTok{wiki_tables[[}\DecValTok{3}\NormalTok{]] }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{html_table}\NormalTok{(}\DataTypeTok{fill =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# check data}
\NormalTok{fall_freshman_stats}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          2017      2016      2015      2014     2013
## 1        Applicants    36,166    35,236    32,723    26,481   26,329
## 2            Admits    28,433    26,961    24,417    20,546   20,251
## 3        % Admitted      78.6      76.5      74.6      77.5     76.9
## 4          Enrolled     7,360     7,753     7,466     7,744    6,881
## 5           Avg GPA      3.43      3.48      3.38      3.37     3.40
## 6        SAT range* 1015–1250 1010–1230 1010–1230 1000–1230 990–1220
## 7 * SAT out of 1600      <NA>      <NA>      <NA>      <NA>     <NA>
\end{verbatim}

Tidy it.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# first column name is blank}
\KeywordTok{colnames}\NormalTok{(fall_freshman_stats)[}\DecValTok{1}\NormalTok{] <-}\StringTok{ "type"}

\CommentTok{# pivot years}
\NormalTok{fall_freshman_stats <-}\StringTok{ }\NormalTok{fall_freshman_stats }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\DataTypeTok{cols =} \StringTok{"2017"}\OperatorTok{:}\StringTok{"2013"}\NormalTok{,}
               \DataTypeTok{names_to =} \StringTok{"year"}\NormalTok{)}

\CommentTok{# make value a number}
\NormalTok{fall_freshman_stats <-}\StringTok{ }\NormalTok{fall_freshman_stats }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{value =} \KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{parse_number}\NormalTok{(value)))}

\CommentTok{# inspect data}
\KeywordTok{glimpse}\NormalTok{(fall_freshman_stats)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 35
## Columns: 3
## $ type  <chr> "Applicants", "Applicants", "Applicants", "Applicants", "Appl...
## $ year  <chr> "2017", "2016", "2015", "2014", "2013", "2017", "2016", "2015...
## $ value <dbl> 36166.00, 35236.00, 32723.00, 26481.00, 26329.00, 28433.00, 2...
\end{verbatim}

Plot it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fall_freshman_stats }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(type }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Applicants"}\NormalTok{, }\StringTok{"Admits"}\NormalTok{, }\StringTok{"Enrolled"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }
             \DataTypeTok{y =}\NormalTok{ value, }
             \DataTypeTok{color =} \KeywordTok{fct_reorder}\NormalTok{(type, value, }\DataTypeTok{.desc =} \OtherTok{TRUE}\NormalTok{))) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{group =}\NormalTok{ type)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{y =} \StringTok{"student count"}\NormalTok{,}
       \DataTypeTok{color =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-177-1.pdf}

\hypertarget{project-proposal}{%
\section{Project Proposal}\label{project-proposal}}

\href{final_project_docs/esoc214_project_proposal.pdf}{Project Proposal} is due next week (Nov.~05, 2020).

\hypertarget{data-case-study-3}{%
\chapter{Data Case Study 3}\label{data-case-study-3}}

For this case study, we will work with the Great American Beer Festival data set, provided as a \href{https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-10-20/readme.md}{tidy tuesday} data set.

As usual, we first load the libraries we are going to use.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Then we load the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beer_awards <-}\StringTok{ }\NormalTok{readr}\OperatorTok{::}\KeywordTok{read_csv}\NormalTok{(}\StringTok{'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-10-20/beer_awards.csv'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   medal = col_character(),
##   beer_name = col_character(),
##   brewery = col_character(),
##   city = col_character(),
##   state = col_character(),
##   category = col_character(),
##   year = col_double()
## )
\end{verbatim}

Take some time to explore this data set. What questions can you ask? What plots can you draw?

\hypertarget{adding-population-info-to-data-frame}{%
\section{Adding population info to data frame}\label{adding-population-info-to-data-frame}}

Whenever you're dealing with states or countries, it's usually relevant to know the population of the different states/countries. For beer awards, we can assume that the higher the population of a state, the higher the number of breweries, thus the higher the number of awards. Let's check if this assumption is correct. First, we need to retrieve information about US states' population numbers. The \texttt{usmap} package has a \texttt{statepop} data set with that info.

First, we need to install \texttt{usmap} and called it with \texttt{library()}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(usmap)}
\end{Highlighting}
\end{Shaded}

We can now inspect the \texttt{statepop} data frame.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(statepop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 51
## Columns: 4
## $ fips     <chr> "01", "02", "04", "05", "06", "08", "09", "10", "11", "12"...
## $ abbr     <chr> "AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "DC", "FL"...
## $ full     <chr> "Alabama", "Alaska", "Arizona", "Arkansas", "California", ...
## $ pop_2015 <dbl> 4858979, 738432, 6828065, 2978204, 39144818, 5456574, 3590...
\end{verbatim}

We just need the \texttt{abbr} and \texttt{pop\_2015} columns, but we have to make sure that the state abbreviation column name matches what we have for our \texttt{beer\_awards} data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{us_pop <-}\StringTok{ }\NormalTok{statepop }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\StringTok{"state"}\NormalTok{ =}\StringTok{ }\NormalTok{abbr,}
\NormalTok{         pop_}\DecValTok{2015}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We are interested in number of beer awards per state, to check whether it correlates with the population size. We need to summarise our \texttt{beer\_awards} data to get number of awards per state.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beer_awards }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(state)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 52 x 2
##    state     n
##    <chr> <int>
##  1 Ak        1
##  2 AK       62
##  3 AL        6
##  4 AR        5
##  5 AZ       92
##  6 CA      962
##  7 CO      659
##  8 CT       16
##  9 DC        4
## 10 DE       43
## # ... with 42 more rows
\end{verbatim}

There are at least two Alaska state codes (Ak and AK). We need to standardize the codes, to upper case, for this count to work correctly. Let's fix that in our original data, so we don't run into this problem again.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beer_awards <-}\StringTok{ }\NormalTok{beer_awards }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{state =} \KeywordTok{toupper}\NormalTok{(state))}
\end{Highlighting}
\end{Shaded}

Now we can count number of awards per state.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{award_count_per_state <-}\StringTok{ }\NormalTok{beer_awards }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(state)}

\CommentTok{# inspect data}
\KeywordTok{glimpse}\NormalTok{(award_count_per_state)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 50
## Columns: 2
## $ state <chr> "AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL", "...
## $ n     <int> 63, 6, 5, 92, 962, 659, 16, 4, 43, 62, 38, 17, 28, 22, 155, 7...
\end{verbatim}

We now can add population info from our \texttt{us\_pop} data frame to our \texttt{award\_count\_per\_state} data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{award_count_per_state <-}\StringTok{ }\KeywordTok{left_join}\NormalTok{(award_count_per_state, us_pop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "state"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# inspect data}
\KeywordTok{glimpse}\NormalTok{(award_count_per_state)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 50
## Columns: 3
## $ state    <chr> "AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL"...
## $ n        <int> 63, 6, 5, 92, 962, 659, 16, 4, 43, 62, 38, 17, 28, 22, 155...
## $ pop_2015 <dbl> 738432, 4858979, 2978204, 6828065, 39144818, 5456574, 3590...
\end{verbatim}

Finally, we draw a scatter plot of award count (\texttt{n}) by population size (\texttt{pop\_2015}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{award_count_per_state }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ pop_}\DecValTok{2015}\NormalTok{, }\DataTypeTok{y =}\NormalTok{ n)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-187-1.pdf}

\hypertarget{plotting-a-map}{%
\section{Plotting a map}\label{plotting-a-map}}

Whenever you have data with locations, like US states, you can think about plotting data to a geographical map. For the US, that's made extra easy with the \texttt{usmap} package.

We can now plot a map, using the \texttt{plot\_usmpa} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beer_awards }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(state, medal) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{plot_usmap}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ ., }\DataTypeTok{values =} \StringTok{"n"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-188-1.pdf}

Let's make it look nicer by moving the legend right.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beer_awards }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(state, medal) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{plot_usmap}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ ., }\DataTypeTok{values =} \StringTok{"n"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"right"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-189-1.pdf}

We can also change the title of the legend.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beer_awards }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(state, medal) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{plot_usmap}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ ., }\DataTypeTok{values =} \StringTok{"n"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"right"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Award Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-190-1.pdf}

People usually associate darker colors with higher density or higher values. Let's change the colors to define a light color for our \texttt{low} values and a dark color for our \texttt{high} values. Check this documentation for \href{http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf}{color names in R}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beer_awards }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(state, medal) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{plot_usmap}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ ., }\DataTypeTok{values =} \StringTok{"n"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"right"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Award Count"}\NormalTok{,}
                        \DataTypeTok{low =} \StringTok{"darkgoldenrod2"}\NormalTok{, }
                        \DataTypeTok{high =} \StringTok{"darkgoldenrod4"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-191-1.pdf}

\hypertarget{data-challenge-07}{%
\section{DATA CHALLENGE 07}\label{data-challenge-07}}

Accept \href{https://classroom.github.com/a/3-61nsVd}{data challenge 07 assignment}

\hypertarget{r-markdown}{%
\chapter{R Markdown}\label{r-markdown}}

Module learning objectives:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Integrate data analysis code and prose in one document
\item
  Use basic formatting for prose
\item
  Use code chunks in R to read data in, and draw tables and plots
\end{enumerate}

\hypertarget{creating-a-new-r-markdown-file}{%
\section{Creating a new R Markdown file}\label{creating-a-new-r-markdown-file}}

To create a new R Markdown file, click on \texttt{New\ File} then choose \texttt{R\ Markdown...}

\includegraphics[width=7.22in]{images/create_rmarkdown_file}

Add a title to your document (no need to change anything else). We are outputting a HTML file. To output other formats, you need to install other software.

\includegraphics[width=22.03in]{images/rmarkdown_popup_window}

The extension for R Markdown files is \texttt{.Rmd} and when you create a new file, it looks like this:

\includegraphics[width=30.22in]{images/new_rmarkdown_file}

The first few lines in your new R Markdown file is an YAML header beginning and ending with \texttt{-\/-\/-}. R code blocks start and end with ```, and the language for the code block is in between curly brackets. Note also that the text contains simple markdown formatting (e.g., \# for headers and stars for bold text).

To \texttt{knit} your R Markdown, click on the \texttt{knit} icon at the top of your file panel.

\includegraphics[width=2in]{images/knit_icon}

\hypertarget{chunk-options}{%
\section{Chunk Options}\label{chunk-options}}

You can change or add knitr options for code chunks, here are some examples:

\begin{itemize}
\item
  include = FALSE/TRUE: sets whether results appear in the finished file. R Markdown runs the code in the chunk regardless of boolean, and the results can be used by other chunks.
\item
  echo = FALSE/TRUE: sets whether code, but not the results, appear in the finished file.
\item
  message = FALSE/TRUE: sets whether messages that are generated by code appear in the finished file.
\item
  warning = FALSE/TRUE: sets whether warnings that are generated by code appear in the finished.
\item
  fig.cap = ``\ldots{}'' adds a caption to graphical results.
\end{itemize}

You can check this \href{https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf?_ga=2.164770041.799329688.1604856038-376910529.1566581971}{R Markdown Reference Guide} for a complete list of knitr chunk options.

\hypertarget{change-yaml-header}{%
\section{Change YAML header}\label{change-yaml-header}}

You can add a table of contents to the top of your document by changing the YAML header like so:

\includegraphics[width=8.67in]{images/toc_header}

For more options for YAML header options check this \href{https://r4ds.had.co.nz/r-markdown.html\#yaml-header}{book chapter}

\hypertarget{text-formatting}{%
\section{Text Formatting}\label{text-formatting}}

\begin{verbatim}
# A level-one heading
## A level-two heading
### A level-two heading
*italics* or _italics_
**bold** or __bold__
`code`
[link description](http://webaddress.com)
- bullet list item
* bullet list item
1. numbered list item
1. second numbered list item (numbers are incremented automatically in the output)

> A block quote.
>
> > A block quote within a block quote.
\end{verbatim}

You can access a R Markdown Cheat Sheet by clicking on \texttt{Help} at the top menu, then choose \texttt{Cheatsheets}.

\hypertarget{reading-data}{%
\section{Reading Data}\label{reading-data}}

First, we need to load tidyverse.

\includegraphics[width=9.03in]{images/load_tidyverse}

Then we can read data in.

\includegraphics[width=13.67in]{images/read_beer_data}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   medal = col_character(),
##   beer_name = col_character(),
##   brewery = col_character(),
##   city = col_character(),
##   state = col_character(),
##   category = col_character(),
##   year = col_double(),
##   macro_category = col_character(),
##   state_area = col_double(),
##   region = col_character(),
##   state_name = col_character(),
##   state_division = col_character()
## )
\end{verbatim}

\hypertarget{data-tables}{%
\section{Data Tables}\label{data-tables}}

Use the function \texttt{kable()} to print out nice tables.

\includegraphics[width=20.06in]{images/nice_table_01}

\begin{table}

\caption{\label{tab:unnamed-chunk-202}Total number of beer awards per region (1987-2020)}
\centering
\begin{tabular}[t]{l|r}
\hline
Region & Total Number of Awards\\
\hline
North Central & 983\\
\hline
Northeast & 537\\
\hline
South & 787\\
\hline
West & 2659\\
\hline
\end{tabular}
\end{table}

Whenever you have results with decimals, you can specify the number of digitis to display.

\includegraphics[width=20.31in]{images/nice_table_02}

\begin{table}

\caption{\label{tab:unnamed-chunk-204}Average number of beer awards per state across regions}
\centering
\begin{tabular}[t]{l|r}
\hline
Region & Average Number of Awards\\
\hline
North Central & 81.92\\
\hline
Northeast & 59.67\\
\hline
South & 52.47\\
\hline
West & 204.54\\
\hline
\end{tabular}
\end{table}

\hypertarget{manual-tables}{%
\section{Manual Tables}\label{manual-tables}}

You might want to add an explanation table that does not come from your data. You can build tables manually in markdown by using the right dashes. Note that the default is left align. You can use \texttt{:} to change that alignment.

\begin{verbatim}
| Tables        | Are           | Cool  |
|---------------|:-------------:|------:|
| row 1 col 1   | row 1 col 2   | $1600 |
| row 2 col 1   | row 2 col 2   |   $12 |
| row 1 col 1   | row 3 col 2   |    $1 |
\end{verbatim}

\begin{longtable}[]{@{}lcr@{}}
\toprule
Tables & Are & Cool\tabularnewline
\midrule
\endhead
row 1 col 1 & row 1 col 2 & \$1600\tabularnewline
row 2 col 1 & row 2 col 2 & \$12\tabularnewline
row 1 col 1 & row 3 col 2 & \$1\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{plots}{%
\section{Plots}\label{plots}}

There are also a number of options that you can use for displaying plots nicely.

\includegraphics[width=20.39in]{images/nice_plot}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-206-1.pdf}

\hypertarget{knitting-pdfs}{%
\section{Knitting PDFs}\label{knitting-pdfs}}

The easiest way to install TeX in your computer (if you don't have TeX/LaTeX installed already) is through the \texttt{tinytext} package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{'tinytex'}\NormalTok{)}
\NormalTok{tinytex}\OperatorTok{::}\KeywordTok{install_tinytex}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Now you can change \texttt{html\_document} to \texttt{pdf\_document} to output a pdf instead of a html file.

\hypertarget{data-challenge-08}{%
\section{DATA CHALLENGE 08}\label{data-challenge-08}}

Accept \href{https://classroom.github.com/a/hsqRqRx1}{data challenge 08 assignment}

\hypertarget{data-case-study-4}{%
\chapter{Data Case Study 4}\label{data-case-study-4}}

The learning objectives of this module are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Apply different parts of the data science workflow, for data import to data visualization, to a new data set
\item
  Build an R script with data wrangling and a R markdown file with the data analysis report
\end{enumerate}

\hypertarget{data}{%
\section{Data}\label{data}}

For this module, we are using \href{https://www.kaggle.com/unanimad/us-election-2020?select=president_county_candidate.csv}{2020 election data from Kaggle}. More specifically, we want the \texttt{president\_county\_candidate.csv} data file.

\hypertarget{data-wrangling-1}{%
\section{Data Wrangling}\label{data-wrangling-1}}

We need to apply the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Read data in R
\item
  Explore data
\item
  Add (with mutate) any other variables we find relevant
\end{enumerate}

\begin{verbatim}
## Rows: 31,139
## Columns: 6
## $ state       <chr> "Delaware", "Delaware", "Delaware", "Delaware", "Delawa...
## $ county      <chr> "Kent County", "Kent County", "Kent County", "Kent Coun...
## $ candidate   <chr> "Joe Biden", "Donald Trump", "Jo Jorgensen", "Howie Haw...
## $ party       <chr> "DEM", "REP", "LIB", "GRN", "DEM", "REP", "LIB", "GRN",...
## $ total_votes <dbl> 44552, 41009, 1044, 420, 195034, 88364, 2953, 1282, 712...
## $ won         <lgl> TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, T...
\end{verbatim}

How many votes total for each candidate?

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-209-1.pdf}

We can get electoral votes per state. The best table I found is from \href{https://en.wikipedia.org/wiki/United_States_Electoral_College\#:~:text=Electoral\%20votes\%2C\%20out\%20of\%20538,entitled\%20to\%20at\%20least\%203.}{wikipedia}

\begin{verbatim}
## Rows: 51
## Columns: 2
## $ state           <chr> "Alabama", "Alaska", "Arizona", "Arkansas", "Califo...
## $ electoral_votes <dbl> 9, 3, 11, 6, 55, 9, 7, 3, 3, 29, 16, 4, 4, 20, 11, ...
\end{verbatim}

How many electoral votes for each candidate? First we need to calculate who won each state.

\begin{verbatim}
## Rows: 51
## Columns: 2
## $ state       <chr> "Alabama", "Alaska", "Arizona", "Arkansas", "California...
## $ total_votes <dbl> 2309900, 334789, 3384972, 1211793, 16822143, 3254844, 1...
\end{verbatim}

\begin{verbatim}
## Rows: 51
## Columns: 5
## Groups: state [51]
## $ state         <chr> "Alabama", "Alaska", "Arizona", "Arkansas", "Californ...
## $ candidate     <chr> "Donald Trump", "Donald Trump", "Joe Biden", "Donald ...
## $ popular_vote  <dbl> 1434159, 179080, 1671491, 758183, 10734181, 1803419, ...
## $ total_votes   <dbl> 2309900, 334789, 3384972, 1211793, 16822143, 3254844,...
## $ perc_pop_vote <dbl> 0.6208749, 0.5349041, 0.4937976, 0.6256704, 0.6380983...
\end{verbatim}

Now we can add electoral votes to winner by state data.

\begin{verbatim}
## Rows: 51
## Columns: 6
## Groups: state [51]
## $ state           <chr> "Alabama", "Alaska", "Arizona", "Arkansas", "Califo...
## $ candidate       <chr> "Donald Trump", "Donald Trump", "Joe Biden", "Donal...
## $ popular_vote    <dbl> 1434159, 179080, 1671491, 758183, 10734181, 1803419...
## $ total_votes     <dbl> 2309900, 334789, 3384972, 1211793, 16822143, 325484...
## $ perc_pop_vote   <dbl> 0.6208749, 0.5349041, 0.4937976, 0.6256704, 0.63809...
## $ electoral_votes <dbl> 9, 3, 11, 6, 55, 9, 7, 3, 3, 29, 16, 4, 4, 20, 11, ...
\end{verbatim}

Plot it!

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-213-1.pdf}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-214-1.pdf}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-215-1.pdf}

\hypertarget{data-challenge-09}{%
\section{DATA CHALLENGE 09}\label{data-challenge-09}}

Accept \href{https://classroom.github.com/a/J1bexrCQ}{data challenge 09 assignment}

\hypertarget{analysis-reporting}{%
\chapter{Analysis Reporting}\label{analysis-reporting}}

Your data analysis is as good as your analysis reporting. You need to make sure you are communicating your data analysis results in a way that makes sense to all of your stakeholders. \href{https://clauswilke.com/dataviz/telling-a-story.html}{Claus Wilke} makes the point that the ``goal in telling a story should be to use facts and logical reasoning'' \citep{wilke2019fundamentals}. That way, you not only make your point, but your point will be remember longer and better.

\hypertarget{types-of-stories}{%
\section{Types of stories}\label{types-of-stories}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lead--Development--Resolution
\item
  Action--Background--Development--Climax--Ending
\item
  Opening--Challenge--Action--Resolution
\end{enumerate}

\hypertarget{telling-a-story}{%
\section{Telling a story}\label{telling-a-story}}

In this module, we will study how multiple tables and plots should be strung together in a story that illustrates the point you want to drive. The simplest way to tell a story is by presenting your visualizations in a challenge-resolution way. What's the lead? What's the development? What's the resolution for the following data analysis?

\includegraphics[width=42.22in]{images/telling_a_story_all}

\hypertarget{how-to-tell-the-story}{%
\subsection{How to tell the story}\label{how-to-tell-the-story}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(janitor)}
\KeywordTok{library}\NormalTok{(knitr)}
\KeywordTok{library}\NormalTok{(tidyverse)}

\NormalTok{women_labor_force_data <-}\StringTok{ }\KeywordTok{read_delim}\NormalTok{(}\StringTok{"data/women_in_labor_force.csv"}\NormalTok{,}
                                     \DataTypeTok{delim =} \StringTok{";"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{clean_names}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   No = col_double(),
##   Country = col_character(),
##   `Level of development` = col_character(),
##   `European Union Membership` = col_character(),
##   Currency = col_character(),
##   `Women Entrepreneurship Index` = col_double(),
##   `Entrepreneurship Index` = col_double(),
##   `Inflation rate` = col_double(),
##   `Female Labor Force Participation Rate` = col_double()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(women_labor_force_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 51
## Columns: 9
## $ no                                    <dbl> 4, 6, 17, 18, 19, 20, 22, 28,...
## $ country                               <chr> "Austria", "Belgium", "Estoni...
## $ level_of_development                  <chr> "Developed", "Developed", "De...
## $ european_union_membership             <chr> "Member", "Member", "Member",...
## $ currency                              <chr> "Euro", "Euro", "Euro", "Euro...
## $ women_entrepreneurship_index          <dbl> 54.9, 63.6, 55.4, 66.4, 68.8,...
## $ entrepreneurship_index                <dbl> 64.9, 65.5, 60.2, 65.7, 67.3,...
## $ inflation_rate                        <dbl> 0.90, 0.60, -0.88, -0.20, 0.0...
## $ female_labor_force_participation_rate <dbl> 67.10, 58.00, 68.50, 67.70, 6...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{women_labor_force_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ level_of_development,}
             \DataTypeTok{y =}\NormalTok{ inflation_rate)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_linedraw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Level of Development"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Inflation Rate"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Inflation by Development across different countries"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-218-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{women_labor_force_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ inflation_rate,}
             \DataTypeTok{x =}\NormalTok{ entrepreneurship_index)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{,}
              \DataTypeTok{formula =}\NormalTok{ y }\OperatorTok{~}\StringTok{ }\NormalTok{x) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_linedraw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Entrepreneurship Index"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Inflation Rate"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Inflation vs. Entrepreneurship"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-219-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\NormalTok{women_labor_force_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ inflation_rate }\OperatorTok{~}\StringTok{ }\NormalTok{entrepreneurship_index) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summary}\NormalTok{() }

\NormalTok{model_}\DecValTok{1}\OperatorTok{$}\NormalTok{coefficients }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r}
\hline
  & Estimate & Std. Error & t value & Pr(>|t|)\\
\hline
(Intercept) & 8.793863 & 2.1751516 & 4.042874 & 0.0001862\\
\hline
entrepreneurship\_index & -0.131373 & 0.0436008 & -3.013090 & 0.0040851\\
\hline
\end{tabular}

The relationship between inflation and entrepreneurship is negative, with inflation going \textbf{down} 0.13 points for each additional point in Entrepreneurship. The linear regression model for this relationship explains 14\% of the variation in the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{women_labor_force_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ inflation_rate,}
             \DataTypeTok{x =}\NormalTok{ women_entrepreneurship_index)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{,}
              \DataTypeTok{formula =}\NormalTok{ y }\OperatorTok{~}\StringTok{ }\NormalTok{x) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_linedraw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Women Entrepreneurship Index"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Inflation Rate"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Inflation vs. Women Entrepreneurship"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/unnamed-chunk-221-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\NormalTok{women_labor_force_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ inflation_rate }\OperatorTok{~}\StringTok{ }\NormalTok{women_entrepreneurship_index) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summary}\NormalTok{()}

\NormalTok{model_}\DecValTok{2}\OperatorTok{$}\NormalTok{coefficients }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r}
\hline
  & Estimate & Std. Error & t value & Pr(>|t|)\\
\hline
(Intercept) & 10.8048470 & 2.3920152 & 4.517048 & 0.0000396\\
\hline
women\_entrepreneurship\_index & -0.1717811 & 0.0479573 & -3.581957 & 0.0007823\\
\hline
\end{tabular}

The relationship between inflation and women entrepreneurship is negative, with inflation going \textbf{down} 0.17 points for each additional point in women entrepreneurship. The linear regression model for this relationship explains 19\% of the variation in the data.

\hypertarget{telling-a-story-well}{%
\section{Telling a story well}\label{telling-a-story-well}}

Here are some general guidelines for telling a story well \citep{wilke2019fundamentals}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Never assume your audience can rapidly process complex visual displays: choose the simplest visualization possible.
\item
  When you're trying to show too much data at once you may end up not showing anything.
\item
  When preparing a presentation or report, aim to use a different type of visualization for each distinct analysis.
\end{enumerate}

\hypertarget{final-project-submission}{%
\section{FINAL PROJECT SUBMISSION}\label{final-project-submission}}

Accept the \href{https://classroom.github.com/a/J-8vd5iB}{final project submission on GitHub}.

\hypertarget{r-markdown-1}{%
\section{R Markdown}\label{r-markdown-1}}

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see \url{http://rmarkdown.rstudio.com}.

When you click the \textbf{Knit} button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(cars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00
\end{verbatim}

\hypertarget{including-plots}{%
\section{Including Plots}\label{including-plots}}

You can also embed plots, for example:

\includegraphics{ESOC_214_Fall_2020_files/figure-latex/pressure-1.pdf}

Note that the \texttt{echo\ =\ FALSE} parameter was added to the code chunk to prevent printing of the R code that generated the plot.

  \bibliography{book.bib,packages.bib}

\end{document}
